{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be677dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_utils import build_tokenizer, build_embedding_matrix, SentenceDataset,Tokenizer, Vocab\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25918a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a86e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: datasets/restaurants_tokenizer.dat\n",
      "loading embedding matrix: datasets/200d_restaurants_embedding_matrix.dat\n"
     ]
    }
   ],
   "source": [
    "# data_files = ['../data/td_lstm_datasets/Laptops_Train.xml', '../data/td_lstm_datasets/Laptops_Test.xml']\n",
    "data_files = ['../data/td_lstm_datasets/Restaurants_Train.xml', '../data/td_lstm_datasets/Restaurants_Test.xml']\n",
    "tokenizer = build_tokenizer(\n",
    "    fnames=data_files,\n",
    "    max_length=80,\n",
    "    data_file='datasets/{0}_tokenizer.dat'.format('restaurants'))\n",
    "embedding_matrix = build_embedding_matrix(\n",
    "    vocab=tokenizer.vocab,\n",
    "    embed_dim=200,\n",
    "    data_file='datasets/{0}d_{1}_embedding_matrix.dat'.format('200', 'restaurants'))\n",
    "trainset = SentenceDataset(data_files[0] , tokenizer, target_dim=3)\n",
    "testset = SentenceDataset(data_files[1] , tokenizer, target_dim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f722e",
   "metadata": {},
   "source": [
    "#### Parameters needs to be set before runnning this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4e7329",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "lr=0.001\n",
    "l2_reg=1e-5\n",
    "num_epoch = 20\n",
    "input_cols = ['text']\n",
    "log_step = 5\n",
    "model_name = 'lstm'\n",
    "dataset = 'restaurant'\n",
    "batch_size = 64\n",
    "embed_dim = 200\n",
    "hidden_dim = 200\n",
    "polarities_dim = 3\n",
    "polarity_dict = {0: 'positive', 1: 'negative', 2:'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159d5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f490beea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset :  {'positive': 2164, 'negative': 808, 'neutral': 639}\n",
      "Testing dataset :  {'positive': 728, 'negative': 197, 'neutral': 198}\n"
     ]
    }
   ],
   "source": [
    "polarity_count_train = {'positive':0, 'negative': 1, 'neutral':2}\n",
    "polarity_count_test = {'positive':0, 'negative': 1, 'neutral':2}\n",
    "for i in train_dataloader:\n",
    "    for polarity in [polarity_dict[int(j)] for j in i['polarity']]:\n",
    "        polarity_count_train[polarity] += 1\n",
    "for i in test_dataloader:\n",
    "    for polarity in [polarity_dict[int(j)] for j in i['polarity']]:\n",
    "        polarity_count_test[polarity] += 1\n",
    "print(\"Training dataset : \" , polarity_count_train)\n",
    "print(\"Testing dataset : \" , polarity_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac94ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicLSTM(nn.Module):\n",
    "    '''\n",
    "    LSTM which can hold variable length sequence, use like TensorFlow's RNN(input, lenght...).\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, batch_first=True, dropout=0,\n",
    "                 bidirectional=False, only_use_last_hidden_state=False, rnn_type='LSTM'):\n",
    "        super(DynamicLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.batch_first = batch_first\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.only_use_last_hidden_state = only_use_last_hidden_state\n",
    "        self.rnn_type = rnn_type\n",
    "        \n",
    "        if self.rnn_type == 'LSTM':\n",
    "            self.RNN = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                               bias=bias, batch_first=batch_first, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif self.rnn_type == 'GRU':\n",
    "            self.RNN = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                              bias=bias, batch_first=batch_first, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif self.rnn_type == 'RNN':\n",
    "            self.RNN = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                              bias=bias, batch_first=batch_first, dropout=dropout, bidirectional=bidirectional)\n",
    "    \n",
    "    def forward(self, x, x_len):\n",
    "        '''\n",
    "        sequence -> sort -> pad and pack -> process using RNN -> unpack -> unsort\n",
    "        '''\n",
    "        '''sort'''\n",
    "        x_sort_idx = torch.sort(x_len, descending=True)[1].long()\n",
    "        x_unsort_idx = torch.sort(x_sort_idx)[1].long()\n",
    "        x_len = x_len[x_sort_idx]\n",
    "        x = x[x_sort_idx]\n",
    "        '''pack'''\n",
    "        x_emb_p = torch.nn.utils.rnn.pack_padded_sequence(x, x_len, batch_first=self.batch_first)\n",
    "        ''' process '''\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            out_pack, (ht, ct) = self.RNN(x_emb_p, None)\n",
    "        else:\n",
    "            out_pack, ht = self.RNN(x_emb_p, None)\n",
    "            ct = None\n",
    "        '''unsort'''\n",
    "        ht = ht[:, x_unsort_idx]\n",
    "        if self.only_use_last_hidden_state:\n",
    "            return ht\n",
    "        else:\n",
    "            out, _ = torch.nn.utils.rnn.pad_packed_sequence(out_pack, batch_first=self.batch_first)\n",
    "            if self.batch_first:\n",
    "                out = out[x_unsort_idx]\n",
    "            else:\n",
    "                out = out[:, x_unsort_idx]\n",
    "            if self.rnn_type == 'LSTM':\n",
    "                ct = ct[:, x_unsort_idx]\n",
    "            return out, (ht, ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b78a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    ''' Standard LSTM '''\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embed = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float))\n",
    "        self.lstm = DynamicLSTM(embed_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_dim, polarities_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        text = inputs[0]\n",
    "        x = self.embed(text)\n",
    "        x_len = torch.sum(text != 0, dim=-1)\n",
    "        _, (h_n, _) = self.lstm(x, x_len)\n",
    "        out = self.dense(h_n[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1219b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(embedding_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be644b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=lr, weight_decay=l2_reg)\n",
    "writer = SummaryWriter(f\"runs/LSTM/BatchSize {batch_size} LR {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c5f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params(model):\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            if len(p.shape) > 1:\n",
    "                torch.nn.init.xavier_normal_(p)\n",
    "            else:\n",
    "                stdv = 1. / (p.shape[0]**0.5)\n",
    "                torch.nn.init.uniform_(p, a=-stdv, b=stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6672d086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trainable_params: 322203, n_nontrainable_params: 889000\n"
     ]
    }
   ],
   "source": [
    "n_trainable_params, n_nontrainable_params = 0, 0\n",
    "for p in model.parameters():\n",
    "    n_params = torch.prod(torch.tensor(p.shape))\n",
    "    if p.requires_grad:\n",
    "        n_trainable_params += n_params\n",
    "    else:\n",
    "        n_nontrainable_params += n_params\n",
    "print('n_trainable_params: {0}, n_nontrainable_params: {1}'.format(n_trainable_params, n_nontrainable_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6731512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, writer, max_test_acc_overall=0, model_name='LSTM'):\n",
    "    max_test_acc = 0\n",
    "    max_f1 = 0\n",
    "    global_step = 0\n",
    "    for epoch in range(num_epoch):\n",
    "        print('>' * 50)\n",
    "        print('epoch:', epoch)\n",
    "        n_correct, n_total = 0, 0\n",
    "        for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "            global_step += 1\n",
    "            # switch model to training mode, clear gradient accumulators\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = [sample_batched[col].to(device) for col in input_cols]\n",
    "            outputs = model(inputs)\n",
    "            targets = sample_batched['polarity'].to(device)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            writer.add_scalar(\"Training loss\", loss, global_step=global_step)\n",
    "            \n",
    "\n",
    "            if global_step % log_step == 0:\n",
    "                n_correct += (torch.argmax(outputs, -1) == targets).sum().item()\n",
    "                n_total += len(outputs)\n",
    "                train_acc = n_correct / n_total\n",
    "                writer.add_scalar(\"Training Accuracy\", \n",
    "                                  train_acc,\n",
    "                                  global_step=global_step)\n",
    "                test_acc, f1 = evaluate(model, writer, global_step)\n",
    "                if test_acc > max_test_acc:\n",
    "                    max_test_acc = test_acc\n",
    "                    if test_acc > max_test_acc_overall:\n",
    "                        if not os.path.exists('state_dict'):\n",
    "                            os.mkdir('state_dict')\n",
    "                        path = './state_dict/{0}_{1}_{2}class_acc{3:.4f}'.format(model_name, dataset, polarities_dim, test_acc)\n",
    "                        torch.save(model.state_dict(), path)\n",
    "                        print('model saved:', path)\n",
    "                if f1 > max_f1:\n",
    "                    max_f1 = f1\n",
    "                print('loss: {:.4f}, acc: {:.4f}, test_acc: {:.4f}, f1: {:.4f}'.format(loss.item(), train_acc, test_acc, f1))\n",
    "    return max_test_acc, max_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e9236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, writer, step):\n",
    "    # switch model to evaluation mode\n",
    "    model.eval()\n",
    "    n_test_correct, n_test_total = 0, 0\n",
    "    t_targets_all, t_outputs_all = None, None\n",
    "    with torch.no_grad():\n",
    "        for t_batch, t_sample_batched in enumerate(test_dataloader):\n",
    "            t_inputs = [t_sample_batched[col].to(device) for col in input_cols]\n",
    "            t_targets = t_sample_batched['polarity'].to(device)\n",
    "            t_outputs = model(t_inputs)\n",
    "\n",
    "            n_test_correct += (torch.argmax(t_outputs, -1) == t_targets).sum().item()\n",
    "            n_test_total += len(t_outputs)\n",
    "\n",
    "            t_targets_all = torch.cat((t_targets_all, t_targets), dim=0) if t_targets_all is not None else t_targets\n",
    "            t_outputs_all = torch.cat((t_outputs_all, t_outputs), dim=0) if t_outputs_all is not None else t_outputs\n",
    "    test_acc = n_test_correct / n_test_total\n",
    "    writer.add_scalar(\"Testing Accuracy\", \n",
    "                                  test_acc,\n",
    "                                  global_step=step)\n",
    "    f1 = metrics.f1_score(t_targets_all.cpu(), torch.argmax(t_outputs_all, -1).cpu(), labels=[0, 1, 2], average='macro')\n",
    "    return test_acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a169cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, writer):\n",
    "    max_test_acc_overall = 0\n",
    "    max_f1_overall = 0\n",
    "    repeats = 1\n",
    "    for i in range(repeats):\n",
    "        print('repeat:', i)\n",
    "        reset_params(model)\n",
    "        max_test_acc, max_f1 = train(model, criterion, optimizer, writer, max_test_acc_overall)\n",
    "        print('max_test_acc: {0}, max_f1: {1}'.format(max_test_acc, max_f1))\n",
    "        max_test_acc_overall = max(max_test_acc, max_test_acc_overall)\n",
    "        max_f1_overall = max(max_f1, max_f1_overall)\n",
    "        print('#' * 50)\n",
    "    print('max_test_acc_overall:', max_test_acc_overall)\n",
    "    print('max_f1_overall:', max_f1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34e2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat: 0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 0\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6500\n",
      "loss: 0.9797, acc: 0.5938, test_acc: 0.6500, f1: 0.2626\n",
      "loss: 1.0987, acc: 0.5391, test_acc: 0.6500, f1: 0.2626\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6527\n",
      "loss: 1.0126, acc: 0.5156, test_acc: 0.6527, f1: 0.2733\n",
      "loss: 0.8358, acc: 0.5547, test_acc: 0.6518, f1: 0.2730\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6554\n",
      "loss: 1.0673, acc: 0.5375, test_acc: 0.6554, f1: 0.2953\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6687\n",
      "loss: 0.9604, acc: 0.5443, test_acc: 0.6687, f1: 0.4316\n",
      "loss: 0.8586, acc: 0.5625, test_acc: 0.6687, f1: 0.3545\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7036\n",
      "loss: 0.9229, acc: 0.5586, test_acc: 0.7036, f1: 0.4815\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7116\n",
      "loss: 0.9131, acc: 0.5625, test_acc: 0.7116, f1: 0.4838\n",
      "loss: 0.6657, acc: 0.5781, test_acc: 0.6857, f1: 0.3936\n",
      "loss: 0.6724, acc: 0.5895, test_acc: 0.6562, f1: 0.4635\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 1\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7134\n",
      "loss: 0.7772, acc: 0.6406, test_acc: 0.7134, f1: 0.4987\n",
      "loss: 0.8013, acc: 0.6328, test_acc: 0.7125, f1: 0.5503\n",
      "loss: 0.7837, acc: 0.6406, test_acc: 0.7045, f1: 0.5230\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7196\n",
      "loss: 0.7170, acc: 0.6445, test_acc: 0.7196, f1: 0.5642\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7384\n",
      "loss: 0.9021, acc: 0.6344, test_acc: 0.7384, f1: 0.5423\n",
      "loss: 0.4100, acc: 0.6823, test_acc: 0.7223, f1: 0.5564\n",
      "loss: 0.5616, acc: 0.7031, test_acc: 0.7098, f1: 0.5444\n",
      "loss: 0.5109, acc: 0.7109, test_acc: 0.7295, f1: 0.5556\n",
      "loss: 0.7950, acc: 0.7101, test_acc: 0.7196, f1: 0.5283\n",
      "loss: 0.7570, acc: 0.7125, test_acc: 0.7268, f1: 0.5546\n",
      "loss: 0.6678, acc: 0.7088, test_acc: 0.7223, f1: 0.5530\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 2\n",
      "loss: 0.5890, acc: 0.7344, test_acc: 0.7170, f1: 0.5537\n",
      "loss: 0.6041, acc: 0.7578, test_acc: 0.7170, f1: 0.5229\n",
      "loss: 0.7096, acc: 0.7552, test_acc: 0.7241, f1: 0.5561\n",
      "loss: 0.6715, acc: 0.7578, test_acc: 0.7295, f1: 0.5827\n",
      "loss: 0.7465, acc: 0.7344, test_acc: 0.7312, f1: 0.5736\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7482\n",
      "loss: 0.5797, acc: 0.7396, test_acc: 0.7482, f1: 0.6335\n",
      "loss: 0.6620, acc: 0.7411, test_acc: 0.7429, f1: 0.5900\n",
      "loss: 0.6543, acc: 0.7383, test_acc: 0.7304, f1: 0.6015\n",
      "loss: 0.6107, acc: 0.7361, test_acc: 0.7232, f1: 0.5388\n",
      "loss: 0.7075, acc: 0.7281, test_acc: 0.7357, f1: 0.5703\n",
      "loss: 0.6694, acc: 0.7273, test_acc: 0.7188, f1: 0.5306\n",
      "loss: 0.6268, acc: 0.7240, test_acc: 0.7321, f1: 0.5866\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 3\n",
      "loss: 0.5446, acc: 0.8125, test_acc: 0.7393, f1: 0.5873\n",
      "loss: 0.4164, acc: 0.8438, test_acc: 0.7420, f1: 0.5953\n",
      "loss: 0.5124, acc: 0.8177, test_acc: 0.7473, f1: 0.6041\n",
      "loss: 0.7463, acc: 0.7891, test_acc: 0.7277, f1: 0.5341\n",
      "loss: 0.6445, acc: 0.7812, test_acc: 0.7446, f1: 0.6172\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7500\n",
      "loss: 0.4036, acc: 0.7865, test_acc: 0.7500, f1: 0.6158\n",
      "loss: 0.7795, acc: 0.7723, test_acc: 0.7357, f1: 0.5512\n",
      "loss: 0.5397, acc: 0.7773, test_acc: 0.7429, f1: 0.5868\n",
      "loss: 0.5110, acc: 0.7795, test_acc: 0.7482, f1: 0.6299\n",
      "loss: 0.5575, acc: 0.7797, test_acc: 0.7455, f1: 0.6256\n",
      "loss: 0.5498, acc: 0.7798, test_acc: 0.7205, f1: 0.5431\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 4\n",
      "loss: 0.5797, acc: 0.7344, test_acc: 0.7196, f1: 0.5305\n",
      "loss: 0.6499, acc: 0.7344, test_acc: 0.7393, f1: 0.5996\n",
      "loss: 0.4744, acc: 0.7500, test_acc: 0.7277, f1: 0.5635\n",
      "loss: 0.6495, acc: 0.7500, test_acc: 0.7411, f1: 0.6181\n",
      "loss: 0.5053, acc: 0.7562, test_acc: 0.7402, f1: 0.5878\n",
      "loss: 0.6170, acc: 0.7578, test_acc: 0.7393, f1: 0.6003\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7518\n",
      "loss: 0.6308, acc: 0.7545, test_acc: 0.7518, f1: 0.6368\n",
      "loss: 0.3895, acc: 0.7656, test_acc: 0.7321, f1: 0.5695\n",
      "loss: 0.6092, acc: 0.7622, test_acc: 0.7321, f1: 0.5887\n",
      "loss: 0.4821, acc: 0.7656, test_acc: 0.7259, f1: 0.5832\n",
      "loss: 0.5888, acc: 0.7685, test_acc: 0.7259, f1: 0.5752\n",
      "loss: 0.8189, acc: 0.7637, test_acc: 0.7339, f1: 0.5777\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 5\n",
      "loss: 0.5175, acc: 0.8125, test_acc: 0.7304, f1: 0.6125\n",
      "loss: 0.4356, acc: 0.8438, test_acc: 0.7438, f1: 0.6039\n",
      "loss: 0.5557, acc: 0.8125, test_acc: 0.7312, f1: 0.5549\n",
      "loss: 0.5664, acc: 0.8086, test_acc: 0.7509, f1: 0.6382\n",
      "loss: 0.4872, acc: 0.8156, test_acc: 0.7321, f1: 0.5603\n",
      "loss: 0.4534, acc: 0.8151, test_acc: 0.7232, f1: 0.5696\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7536\n",
      "loss: 0.6322, acc: 0.8058, test_acc: 0.7536, f1: 0.6464\n",
      "loss: 0.4416, acc: 0.8086, test_acc: 0.7286, f1: 0.5639\n",
      "loss: 0.4452, acc: 0.8108, test_acc: 0.7402, f1: 0.6146\n",
      "loss: 0.5087, acc: 0.8031, test_acc: 0.7286, f1: 0.5596\n",
      "loss: 0.4735, acc: 0.8026, test_acc: 0.7312, f1: 0.5864\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 6\n",
      "loss: 0.4144, acc: 0.8750, test_acc: 0.7339, f1: 0.6000\n",
      "loss: 0.4249, acc: 0.8672, test_acc: 0.7250, f1: 0.5498\n",
      "loss: 0.4627, acc: 0.8438, test_acc: 0.7304, f1: 0.6001\n",
      "loss: 0.5384, acc: 0.8203, test_acc: 0.7250, f1: 0.5798\n",
      "loss: 0.4530, acc: 0.8219, test_acc: 0.7214, f1: 0.5375\n",
      "loss: 0.5925, acc: 0.8099, test_acc: 0.7134, f1: 0.5629\n",
      "loss: 0.4690, acc: 0.8125, test_acc: 0.7143, f1: 0.5940\n",
      "loss: 0.4518, acc: 0.8145, test_acc: 0.7295, f1: 0.5557\n",
      "loss: 0.5496, acc: 0.8073, test_acc: 0.7330, f1: 0.5698\n",
      "loss: 0.5853, acc: 0.8016, test_acc: 0.7375, f1: 0.6098\n",
      "loss: 0.4756, acc: 0.8054, test_acc: 0.7170, f1: 0.5267\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 7\n",
      "loss: 0.4492, acc: 0.8281, test_acc: 0.7134, f1: 0.5149\n",
      "loss: 0.3641, acc: 0.8594, test_acc: 0.7304, f1: 0.5902\n",
      "loss: 0.4648, acc: 0.8385, test_acc: 0.7232, f1: 0.5907\n",
      "loss: 0.4728, acc: 0.8281, test_acc: 0.7286, f1: 0.5931\n",
      "loss: 0.3849, acc: 0.8313, test_acc: 0.7196, f1: 0.5830\n",
      "loss: 0.4197, acc: 0.8255, test_acc: 0.7161, f1: 0.5687\n",
      "loss: 0.3758, acc: 0.8304, test_acc: 0.7304, f1: 0.5695\n",
      "loss: 0.5200, acc: 0.8301, test_acc: 0.7330, f1: 0.6111\n",
      "loss: 0.4121, acc: 0.8316, test_acc: 0.7393, f1: 0.6078\n",
      "loss: 0.4996, acc: 0.8234, test_acc: 0.7393, f1: 0.5981\n",
      "loss: 0.4671, acc: 0.8168, test_acc: 0.7259, f1: 0.5812\n",
      "loss: 0.3966, acc: 0.8190, test_acc: 0.7304, f1: 0.5930\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 8\n",
      "loss: 0.4281, acc: 0.8438, test_acc: 0.7348, f1: 0.5701\n",
      "loss: 0.3089, acc: 0.8594, test_acc: 0.7384, f1: 0.6046\n",
      "loss: 0.3908, acc: 0.8542, test_acc: 0.7429, f1: 0.6011\n",
      "loss: 0.4846, acc: 0.8320, test_acc: 0.7357, f1: 0.6149\n",
      "loss: 0.5554, acc: 0.8250, test_acc: 0.7232, f1: 0.5781\n",
      "loss: 0.5762, acc: 0.8125, test_acc: 0.7223, f1: 0.6038\n",
      "loss: 0.4071, acc: 0.8125, test_acc: 0.7295, f1: 0.5969\n",
      "loss: 0.3783, acc: 0.8164, test_acc: 0.7205, f1: 0.5485\n",
      "loss: 0.4141, acc: 0.8194, test_acc: 0.7259, f1: 0.5811\n",
      "loss: 0.3799, acc: 0.8234, test_acc: 0.7241, f1: 0.5931\n",
      "loss: 0.5639, acc: 0.8182, test_acc: 0.7223, f1: 0.5711\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 9\n",
      "loss: 0.2491, acc: 0.9219, test_acc: 0.7205, f1: 0.5950\n",
      "loss: 0.3260, acc: 0.8984, test_acc: 0.7268, f1: 0.5578\n",
      "loss: 0.3480, acc: 0.8854, test_acc: 0.7321, f1: 0.5654\n",
      "loss: 0.4960, acc: 0.8633, test_acc: 0.7277, f1: 0.5866\n",
      "loss: 0.4030, acc: 0.8562, test_acc: 0.7411, f1: 0.5977\n",
      "loss: 0.3779, acc: 0.8516, test_acc: 0.7357, f1: 0.6118\n",
      "loss: 0.2325, acc: 0.8616, test_acc: 0.7393, f1: 0.5899\n",
      "loss: 0.4004, acc: 0.8613, test_acc: 0.7241, f1: 0.5756\n",
      "loss: 0.5054, acc: 0.8472, test_acc: 0.7241, f1: 0.5903\n",
      "loss: 0.4376, acc: 0.8453, test_acc: 0.7259, f1: 0.5758\n",
      "loss: 0.4267, acc: 0.8423, test_acc: 0.7277, f1: 0.5783\n",
      "loss: 0.4794, acc: 0.8393, test_acc: 0.7098, f1: 0.5850\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 10\n",
      "loss: 0.2503, acc: 0.9062, test_acc: 0.7232, f1: 0.5764\n",
      "loss: 0.3331, acc: 0.8984, test_acc: 0.7179, f1: 0.5572\n",
      "loss: 0.2938, acc: 0.8854, test_acc: 0.7116, f1: 0.5830\n",
      "loss: 0.3568, acc: 0.8789, test_acc: 0.7152, f1: 0.5757\n",
      "loss: 0.4757, acc: 0.8625, test_acc: 0.7036, f1: 0.5545\n",
      "loss: 0.3987, acc: 0.8568, test_acc: 0.7098, f1: 0.5431\n",
      "loss: 0.3809, acc: 0.8460, test_acc: 0.7170, f1: 0.5745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3285, acc: 0.8496, test_acc: 0.7366, f1: 0.5942\n",
      "loss: 0.4388, acc: 0.8385, test_acc: 0.7411, f1: 0.5921\n",
      "loss: 0.3605, acc: 0.8453, test_acc: 0.7429, f1: 0.6105\n",
      "loss: 0.3523, acc: 0.8466, test_acc: 0.7411, f1: 0.6236\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 11\n",
      "loss: 0.4242, acc: 0.8438, test_acc: 0.7429, f1: 0.5817\n",
      "loss: 0.3894, acc: 0.8438, test_acc: 0.7384, f1: 0.5831\n",
      "loss: 0.3296, acc: 0.8490, test_acc: 0.7295, f1: 0.6007\n",
      "loss: 0.2688, acc: 0.8516, test_acc: 0.7286, f1: 0.5831\n",
      "loss: 0.4536, acc: 0.8500, test_acc: 0.7286, f1: 0.5819\n",
      "loss: 0.5041, acc: 0.8255, test_acc: 0.7312, f1: 0.5923\n",
      "loss: 0.3244, acc: 0.8326, test_acc: 0.7259, f1: 0.6152\n",
      "loss: 0.3268, acc: 0.8359, test_acc: 0.7464, f1: 0.6082\n",
      "loss: 0.3493, acc: 0.8403, test_acc: 0.7214, f1: 0.5734\n",
      "loss: 0.2356, acc: 0.8438, test_acc: 0.7286, f1: 0.5884\n",
      "loss: 0.4331, acc: 0.8381, test_acc: 0.7170, f1: 0.5691\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 12\n",
      "loss: 0.2426, acc: 0.9219, test_acc: 0.7268, f1: 0.5967\n",
      "loss: 0.3457, acc: 0.8906, test_acc: 0.7402, f1: 0.5722\n",
      "loss: 0.2598, acc: 0.8854, test_acc: 0.7339, f1: 0.5847\n",
      "loss: 0.2580, acc: 0.8750, test_acc: 0.7286, f1: 0.6196\n",
      "loss: 0.3888, acc: 0.8656, test_acc: 0.7402, f1: 0.6125\n",
      "loss: 0.3913, acc: 0.8594, test_acc: 0.7384, f1: 0.5901\n",
      "loss: 0.3800, acc: 0.8527, test_acc: 0.7402, f1: 0.6011\n",
      "loss: 0.2467, acc: 0.8613, test_acc: 0.7366, f1: 0.6031\n",
      "loss: 0.4093, acc: 0.8524, test_acc: 0.7348, f1: 0.6190\n",
      "loss: 0.4946, acc: 0.8453, test_acc: 0.7402, f1: 0.5936\n",
      "loss: 0.4767, acc: 0.8381, test_acc: 0.7312, f1: 0.5627\n",
      "loss: 0.4135, acc: 0.8398, test_acc: 0.7196, f1: 0.5777\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 13\n",
      "loss: 0.2241, acc: 0.8594, test_acc: 0.7348, f1: 0.6015\n",
      "loss: 0.2442, acc: 0.8828, test_acc: 0.7375, f1: 0.6102\n",
      "loss: 0.2434, acc: 0.8854, test_acc: 0.7268, f1: 0.5944\n",
      "loss: 0.3998, acc: 0.8711, test_acc: 0.7268, f1: 0.5769\n",
      "loss: 0.4091, acc: 0.8625, test_acc: 0.7250, f1: 0.5637\n",
      "loss: 0.3295, acc: 0.8620, test_acc: 0.7196, f1: 0.5949\n",
      "loss: 0.3328, acc: 0.8594, test_acc: 0.7295, f1: 0.6093\n",
      "loss: 0.4277, acc: 0.8496, test_acc: 0.7455, f1: 0.6125\n",
      "loss: 0.4984, acc: 0.8438, test_acc: 0.7321, f1: 0.5840\n",
      "loss: 0.2643, acc: 0.8469, test_acc: 0.7250, f1: 0.5852\n",
      "loss: 0.3308, acc: 0.8480, test_acc: 0.7241, f1: 0.5773\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 14\n",
      "loss: 0.2251, acc: 0.8750, test_acc: 0.7286, f1: 0.5875\n",
      "loss: 0.2119, acc: 0.8984, test_acc: 0.7312, f1: 0.5810\n",
      "loss: 0.2654, acc: 0.8958, test_acc: 0.7402, f1: 0.5987\n",
      "loss: 0.2023, acc: 0.8984, test_acc: 0.7339, f1: 0.6025\n",
      "loss: 0.1805, acc: 0.9000, test_acc: 0.7429, f1: 0.6276\n",
      "loss: 0.1431, acc: 0.9089, test_acc: 0.7312, f1: 0.5757\n",
      "loss: 0.3253, acc: 0.9018, test_acc: 0.7205, f1: 0.5693\n",
      "loss: 0.1713, acc: 0.9062, test_acc: 0.7304, f1: 0.5832\n",
      "loss: 0.3227, acc: 0.9062, test_acc: 0.7312, f1: 0.6102\n",
      "loss: 0.3576, acc: 0.8984, test_acc: 0.7241, f1: 0.5834\n",
      "loss: 0.4208, acc: 0.8920, test_acc: 0.7357, f1: 0.5854\n",
      "loss: 0.2999, acc: 0.8901, test_acc: 0.7241, f1: 0.5887\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 15\n",
      "loss: 0.2282, acc: 0.8906, test_acc: 0.7205, f1: 0.5786\n",
      "loss: 0.1949, acc: 0.8984, test_acc: 0.7196, f1: 0.5784\n",
      "loss: 0.2043, acc: 0.9115, test_acc: 0.7170, f1: 0.5801\n",
      "loss: 0.3152, acc: 0.8906, test_acc: 0.7241, f1: 0.5769\n",
      "loss: 0.2439, acc: 0.8938, test_acc: 0.7259, f1: 0.5704\n",
      "loss: 0.1995, acc: 0.8958, test_acc: 0.7312, f1: 0.5835\n",
      "loss: 0.3172, acc: 0.8906, test_acc: 0.7214, f1: 0.5763\n",
      "loss: 0.3836, acc: 0.8828, test_acc: 0.7250, f1: 0.6003\n",
      "loss: 0.3213, acc: 0.8767, test_acc: 0.7250, f1: 0.5720\n",
      "loss: 0.3034, acc: 0.8766, test_acc: 0.7357, f1: 0.5954\n",
      "loss: 0.3607, acc: 0.8707, test_acc: 0.7339, f1: 0.5898\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 16\n",
      "loss: 0.3347, acc: 0.8594, test_acc: 0.7295, f1: 0.5939\n",
      "loss: 0.3162, acc: 0.8516, test_acc: 0.7411, f1: 0.6016\n",
      "loss: 0.2991, acc: 0.8542, test_acc: 0.7295, f1: 0.5825\n",
      "loss: 0.1621, acc: 0.8750, test_acc: 0.7402, f1: 0.5890\n",
      "loss: 0.2070, acc: 0.8844, test_acc: 0.7304, f1: 0.5811\n",
      "loss: 0.2722, acc: 0.8854, test_acc: 0.7232, f1: 0.5889\n",
      "loss: 0.3422, acc: 0.8817, test_acc: 0.7241, f1: 0.5907\n",
      "loss: 0.2657, acc: 0.8789, test_acc: 0.7312, f1: 0.5688\n",
      "loss: 0.2822, acc: 0.8785, test_acc: 0.7321, f1: 0.5912\n",
      "loss: 0.3749, acc: 0.8719, test_acc: 0.7455, f1: 0.6348\n",
      "loss: 0.3393, acc: 0.8651, test_acc: 0.7491, f1: 0.6329\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 17\n",
      "loss: 0.3347, acc: 0.8281, test_acc: 0.7375, f1: 0.5912\n",
      "loss: 0.2570, acc: 0.8594, test_acc: 0.7429, f1: 0.5912\n",
      "loss: 0.2621, acc: 0.8802, test_acc: 0.7330, f1: 0.5847\n",
      "loss: 0.2649, acc: 0.8750, test_acc: 0.7321, f1: 0.5905\n",
      "loss: 0.1711, acc: 0.8844, test_acc: 0.7339, f1: 0.5964\n",
      "loss: 0.2404, acc: 0.8828, test_acc: 0.7366, f1: 0.5985\n",
      "loss: 0.3379, acc: 0.8772, test_acc: 0.7429, f1: 0.5992\n",
      "loss: 0.2525, acc: 0.8750, test_acc: 0.7455, f1: 0.6081\n",
      "loss: 0.2718, acc: 0.8767, test_acc: 0.7312, f1: 0.6007\n",
      "loss: 0.3716, acc: 0.8703, test_acc: 0.7250, f1: 0.5865\n",
      "loss: 0.3361, acc: 0.8651, test_acc: 0.7205, f1: 0.5623\n",
      "loss: 0.2989, acc: 0.8646, test_acc: 0.7214, f1: 0.5691\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 18\n",
      "loss: 0.1782, acc: 0.9062, test_acc: 0.7277, f1: 0.5852\n",
      "loss: 0.2724, acc: 0.8984, test_acc: 0.7357, f1: 0.6017\n",
      "loss: 0.2396, acc: 0.8906, test_acc: 0.7304, f1: 0.5859\n",
      "loss: 0.2041, acc: 0.8945, test_acc: 0.7188, f1: 0.5791\n",
      "loss: 0.2812, acc: 0.8844, test_acc: 0.7232, f1: 0.5814\n",
      "loss: 0.2202, acc: 0.8854, test_acc: 0.7330, f1: 0.5947\n",
      "loss: 0.4147, acc: 0.8661, test_acc: 0.7232, f1: 0.5814\n",
      "loss: 0.2703, acc: 0.8652, test_acc: 0.7196, f1: 0.5741\n",
      "loss: 0.2932, acc: 0.8646, test_acc: 0.7223, f1: 0.5639\n",
      "loss: 0.3260, acc: 0.8656, test_acc: 0.7223, f1: 0.5669\n",
      "loss: 0.1993, acc: 0.8707, test_acc: 0.7241, f1: 0.5816\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 19\n",
      "loss: 0.3069, acc: 0.8438, test_acc: 0.7366, f1: 0.5928\n",
      "loss: 0.2546, acc: 0.8594, test_acc: 0.7357, f1: 0.5812\n",
      "loss: 0.2221, acc: 0.8854, test_acc: 0.7259, f1: 0.5903\n",
      "loss: 0.1796, acc: 0.8945, test_acc: 0.7241, f1: 0.5847\n",
      "loss: 0.2675, acc: 0.8875, test_acc: 0.7188, f1: 0.5645\n",
      "loss: 0.2304, acc: 0.8906, test_acc: 0.7107, f1: 0.5740\n",
      "loss: 0.1757, acc: 0.8973, test_acc: 0.7116, f1: 0.5665\n",
      "loss: 0.2697, acc: 0.8906, test_acc: 0.7116, f1: 0.5576\n",
      "loss: 0.3229, acc: 0.8854, test_acc: 0.7152, f1: 0.5639\n",
      "loss: 0.2801, acc: 0.8844, test_acc: 0.7205, f1: 0.5647\n",
      "loss: 0.2830, acc: 0.8835, test_acc: 0.7241, f1: 0.5844\n",
      "loss: 0.2943, acc: 0.8805, test_acc: 0.7214, f1: 0.5832\n",
      "max_test_acc: 0.7535714285714286, max_f1: 0.6464297024297024\n",
      "##################################################\n",
      "max_test_acc_overall: 0.7535714285714286\n",
      "max_f1_overall: 0.6464297024297024\n"
     ]
    }
   ],
   "source": [
    "run(model, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dcff5f",
   "metadata": {},
   "source": [
    "### Run the latest saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b6281ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(4445, 200)\n",
       "  (lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(200, 200, batch_first=True)\n",
       "  )\n",
       "  (dense): Linear(in_features=200, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_file = sorted([os.path.join('state_dict',path) for path in os.listdir('state_dict')], key=os.path.getmtime)[-1]\n",
    "checkpoints = torch.load(latest_file)\n",
    "model.load_state_dict(checkpoints)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb4e68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = torch.tensor(tokenizer.text_to_sequence(\"Keyboard is great, very quiet for all the typing that I do.\"))\n",
    "output = model(sample_data.reshape(1,1,-1))\n",
    "polarity_dict[int(torch.argmax(output, -1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96723172",
   "metadata": {},
   "source": [
    "#### Parameters needs to be set before runnning this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77f378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "lr=0.001\n",
    "l2_reg=1e-5\n",
    "num_epoch = 20\n",
    "input_cols = ['text', 'aspect']\n",
    "log_step = 5\n",
    "model_name = 'ae_lstm'\n",
    "dataset = 'restaurant'\n",
    "batch_size = 64\n",
    "embed_dim = 200\n",
    "hidden_dim = 200\n",
    "polarities_dim = 3\n",
    "polarity_dict = {0: 'positive', 1: 'negative', 2:'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f320b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeEmbedding(nn.Module):\n",
    "    '''\n",
    "    Squeeze sequence embedding length to the longest one in the batch\n",
    "    '''\n",
    "    def __init__(self, batch_first=True):\n",
    "        super(SqueezeEmbedding, self).__init__()\n",
    "        self.batch_first = batch_first\n",
    "    \n",
    "    def forward(self, x, x_len):\n",
    "        '''\n",
    "        sequence -> sort -> pad and pack -> unpack -> unsort\n",
    "        '''\n",
    "        '''sort'''\n",
    "        x_sort_idx = torch.sort(x_len, descending=True)[1].long()\n",
    "        x_unsort_idx = torch.sort(x_sort_idx)[1].long()\n",
    "        x_len = x_len[x_sort_idx]\n",
    "        x = x[x_sort_idx]\n",
    "        '''pack'''\n",
    "        x_emb_p = torch.nn.utils.rnn.pack_padded_sequence(x, x_len, batch_first=self.batch_first)\n",
    "        '''unpack'''\n",
    "        out, _ = torch.nn.utils.rnn.pad_packed_sequence(x_emb_p, batch_first=self.batch_first)\n",
    "        if self.batch_first:\n",
    "            out = out[x_unsort_idx]\n",
    "        else:\n",
    "            out = out[:, x_unsort_idx]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7647a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_LSTM(nn.Module):\n",
    "    ''' LSTM with Aspect Embedding '''\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super(AE_LSTM, self).__init__()\n",
    "        self.embed = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float))\n",
    "        self.squeeze_embedding = SqueezeEmbedding()\n",
    "        self.lstm = DynamicLSTM(embed_dim*2, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_dim, polarities_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        text, aspect_text = inputs[0], inputs[1]\n",
    "        x_len = torch.sum(text != 0, dim=-1)\n",
    "        x_len_max = torch.max(x_len)\n",
    "        aspect_len = torch.sum(aspect_text != 0, dim=-1).float()\n",
    "        \n",
    "        x = self.embed(text)\n",
    "        x = self.squeeze_embedding(x, x_len)\n",
    "        aspect = self.embed(aspect_text)\n",
    "        aspect_pool = torch.div(torch.sum(aspect, dim=1), aspect_len.view(aspect_len.size(0), 1))\n",
    "        aspect = torch.unsqueeze(aspect_pool, dim=1).expand(-1, x_len_max, -1)\n",
    "        x = torch.cat((aspect, x), dim=-1)\n",
    "        \n",
    "        _, (h_n, _) = self.lstm(x, x_len)\n",
    "        out = self.dense(h_n[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54f020f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AE = AE_LSTM(embedding_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bfbec64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_LSTM(\n",
       "  (embed): Embedding(4445, 200)\n",
       "  (squeeze_embedding): SqueezeEmbedding()\n",
       "  (lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(400, 200, batch_first=True)\n",
       "  )\n",
       "  (dense): Linear(in_features=200, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41fbefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "params = filter(lambda p: p.requires_grad, model_AE.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=lr, weight_decay=l2_reg)\n",
    "writer_AE = SummaryWriter(f\"runs/AE_LSTM/BatchSize {batch_size} LR {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d54a307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat: 0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 0\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6500\n",
      "loss: 1.0001, acc: 0.6250, test_acc: 0.6500, f1: 0.2626\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6589\n",
      "loss: 0.9891, acc: 0.5781, test_acc: 0.6589, f1: 0.3261\n",
      "loss: 0.8990, acc: 0.6042, test_acc: 0.6491, f1: 0.4143\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6696\n",
      "loss: 0.9310, acc: 0.6016, test_acc: 0.6696, f1: 0.3654\n",
      "loss: 0.9313, acc: 0.6000, test_acc: 0.6607, f1: 0.3242\n",
      "loss: 0.8754, acc: 0.6094, test_acc: 0.6607, f1: 0.3262\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6732\n",
      "loss: 0.7158, acc: 0.6250, test_acc: 0.6732, f1: 0.3840\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6830\n",
      "loss: 0.8197, acc: 0.6289, test_acc: 0.6830, f1: 0.4338\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6848\n",
      "loss: 0.8430, acc: 0.6337, test_acc: 0.6848, f1: 0.4355\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6893\n",
      "loss: 0.7542, acc: 0.6406, test_acc: 0.6893, f1: 0.4435\n",
      "loss: 0.8731, acc: 0.6435, test_acc: 0.6714, f1: 0.4737\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 1\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7018\n",
      "loss: 0.7246, acc: 0.7188, test_acc: 0.7018, f1: 0.5071\n",
      "loss: 0.7805, acc: 0.6875, test_acc: 0.6982, f1: 0.4716\n",
      "loss: 0.6513, acc: 0.6927, test_acc: 0.6973, f1: 0.4785\n",
      "loss: 0.6971, acc: 0.6914, test_acc: 0.6438, f1: 0.5221\n",
      "loss: 0.5460, acc: 0.7188, test_acc: 0.6982, f1: 0.4558\n",
      "loss: 0.6095, acc: 0.7240, test_acc: 0.6964, f1: 0.5127\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7071\n",
      "loss: 0.7002, acc: 0.7210, test_acc: 0.7071, f1: 0.4825\n",
      "loss: 0.7498, acc: 0.7148, test_acc: 0.7018, f1: 0.4604\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7161\n",
      "loss: 0.5939, acc: 0.7170, test_acc: 0.7161, f1: 0.5341\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7286\n",
      "loss: 0.7436, acc: 0.7141, test_acc: 0.7286, f1: 0.5795\n",
      "loss: 0.7131, acc: 0.7102, test_acc: 0.7000, f1: 0.5492\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 2\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7348\n",
      "loss: 0.6219, acc: 0.7656, test_acc: 0.7348, f1: 0.5592\n",
      "loss: 0.7562, acc: 0.7031, test_acc: 0.7312, f1: 0.6119\n",
      "loss: 0.6850, acc: 0.6979, test_acc: 0.7107, f1: 0.6115\n",
      "loss: 0.6280, acc: 0.6992, test_acc: 0.7116, f1: 0.4877\n",
      "loss: 0.7438, acc: 0.7000, test_acc: 0.7143, f1: 0.4777\n",
      "loss: 0.6193, acc: 0.7109, test_acc: 0.7286, f1: 0.5406\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7357\n",
      "loss: 0.5440, acc: 0.7143, test_acc: 0.7357, f1: 0.5989\n",
      "loss: 0.4923, acc: 0.7246, test_acc: 0.7232, f1: 0.6095\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7420\n",
      "loss: 0.6444, acc: 0.7205, test_acc: 0.7420, f1: 0.5670\n",
      "loss: 0.8734, acc: 0.7063, test_acc: 0.7214, f1: 0.5663\n",
      "loss: 0.6522, acc: 0.7088, test_acc: 0.7205, f1: 0.5952\n",
      "loss: 0.6649, acc: 0.7070, test_acc: 0.7321, f1: 0.5711\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 3\n",
      "loss: 0.5534, acc: 0.7812, test_acc: 0.7188, f1: 0.5362\n",
      "loss: 0.5361, acc: 0.8047, test_acc: 0.7205, f1: 0.5575\n",
      "loss: 0.7635, acc: 0.7552, test_acc: 0.7125, f1: 0.5700\n",
      "loss: 0.5979, acc: 0.7773, test_acc: 0.7304, f1: 0.5831\n",
      "loss: 0.5227, acc: 0.7781, test_acc: 0.7384, f1: 0.5915\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7446\n",
      "loss: 0.4409, acc: 0.7891, test_acc: 0.7446, f1: 0.6145\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7536\n",
      "loss: 0.5798, acc: 0.7835, test_acc: 0.7536, f1: 0.6124\n",
      "loss: 0.5249, acc: 0.7832, test_acc: 0.7491, f1: 0.6161\n",
      "loss: 0.7133, acc: 0.7691, test_acc: 0.7464, f1: 0.6309\n",
      "loss: 0.7281, acc: 0.7594, test_acc: 0.7491, f1: 0.6252\n",
      "loss: 0.3962, acc: 0.7713, test_acc: 0.7393, f1: 0.5721\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 4\n",
      "loss: 0.3600, acc: 0.9219, test_acc: 0.7089, f1: 0.5700\n",
      "loss: 0.5264, acc: 0.8672, test_acc: 0.7232, f1: 0.5731\n",
      "loss: 0.6136, acc: 0.8333, test_acc: 0.7366, f1: 0.6079\n",
      "loss: 0.5576, acc: 0.8359, test_acc: 0.7384, f1: 0.5782\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7554\n",
      "loss: 0.4638, acc: 0.8406, test_acc: 0.7554, f1: 0.6332\n",
      "loss: 0.4774, acc: 0.8307, test_acc: 0.7554, f1: 0.6395\n",
      "loss: 0.3983, acc: 0.8326, test_acc: 0.7491, f1: 0.6072\n",
      "loss: 0.5085, acc: 0.8281, test_acc: 0.7527, f1: 0.6088\n",
      "loss: 0.5276, acc: 0.8229, test_acc: 0.7491, f1: 0.6227\n",
      "loss: 0.5867, acc: 0.8219, test_acc: 0.7482, f1: 0.6327\n",
      "loss: 0.6903, acc: 0.8111, test_acc: 0.7402, f1: 0.5971\n",
      "loss: 0.6048, acc: 0.8091, test_acc: 0.7464, f1: 0.6055\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 5\n",
      "loss: 0.4768, acc: 0.7969, test_acc: 0.7420, f1: 0.6070\n",
      "loss: 0.4358, acc: 0.7969, test_acc: 0.7402, f1: 0.6000\n",
      "loss: 0.3067, acc: 0.8333, test_acc: 0.7455, f1: 0.6241\n",
      "loss: 0.4547, acc: 0.8281, test_acc: 0.7393, f1: 0.5975\n",
      "loss: 0.4102, acc: 0.8187, test_acc: 0.7420, f1: 0.6101\n",
      "loss: 0.4251, acc: 0.8255, test_acc: 0.7402, f1: 0.5995\n",
      "loss: 0.5703, acc: 0.8147, test_acc: 0.7393, f1: 0.6093\n",
      "loss: 0.3089, acc: 0.8223, test_acc: 0.7384, f1: 0.5913\n",
      "loss: 0.4473, acc: 0.8177, test_acc: 0.7402, f1: 0.5896\n",
      "loss: 0.5054, acc: 0.8156, test_acc: 0.7455, f1: 0.6326\n",
      "loss: 0.4410, acc: 0.8125, test_acc: 0.7438, f1: 0.6273\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 6\n",
      "loss: 0.1498, acc: 0.9688, test_acc: 0.7482, f1: 0.6042\n",
      "loss: 0.3847, acc: 0.9297, test_acc: 0.7455, f1: 0.6309\n",
      "loss: 0.4126, acc: 0.9010, test_acc: 0.7384, f1: 0.6138\n",
      "loss: 0.3811, acc: 0.8789, test_acc: 0.7402, f1: 0.5887\n",
      "loss: 0.3725, acc: 0.8781, test_acc: 0.7446, f1: 0.6170\n",
      "loss: 0.2760, acc: 0.8776, test_acc: 0.7500, f1: 0.6161\n",
      "loss: 0.4089, acc: 0.8728, test_acc: 0.7518, f1: 0.6448\n",
      "loss: 0.2001, acc: 0.8789, test_acc: 0.7375, f1: 0.6209\n",
      "loss: 0.2834, acc: 0.8837, test_acc: 0.7536, f1: 0.6344\n",
      "loss: 0.3970, acc: 0.8797, test_acc: 0.7482, f1: 0.6260\n",
      "loss: 0.5201, acc: 0.8722, test_acc: 0.7473, f1: 0.6439\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 7\n",
      "loss: 0.2177, acc: 0.9531, test_acc: 0.7518, f1: 0.6285\n",
      "loss: 0.4046, acc: 0.8672, test_acc: 0.7518, f1: 0.6379\n",
      "loss: 0.1986, acc: 0.8854, test_acc: 0.7509, f1: 0.6518\n",
      "loss: 0.3184, acc: 0.8828, test_acc: 0.7509, f1: 0.6283\n",
      "loss: 0.2961, acc: 0.8844, test_acc: 0.7429, f1: 0.6049\n",
      "loss: 0.4858, acc: 0.8750, test_acc: 0.7420, f1: 0.5964\n",
      "loss: 0.2780, acc: 0.8772, test_acc: 0.7446, f1: 0.6372\n",
      "loss: 0.2813, acc: 0.8770, test_acc: 0.7464, f1: 0.5979\n",
      "loss: 0.2648, acc: 0.8802, test_acc: 0.7411, f1: 0.6032\n",
      "loss: 0.3077, acc: 0.8797, test_acc: 0.7348, f1: 0.6224\n",
      "loss: 0.2600, acc: 0.8835, test_acc: 0.7330, f1: 0.5934\n",
      "loss: 0.4210, acc: 0.8737, test_acc: 0.7402, f1: 0.6196\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 8\n",
      "loss: 0.1464, acc: 0.9688, test_acc: 0.7491, f1: 0.6289\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7571\n",
      "loss: 0.1994, acc: 0.9375, test_acc: 0.7571, f1: 0.6319\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7589\n",
      "loss: 0.1384, acc: 0.9427, test_acc: 0.7589, f1: 0.6351\n",
      "loss: 0.2788, acc: 0.9336, test_acc: 0.7455, f1: 0.6105\n",
      "loss: 0.2500, acc: 0.9250, test_acc: 0.7429, f1: 0.6203\n",
      "loss: 0.3072, acc: 0.9245, test_acc: 0.7446, f1: 0.6417\n",
      "loss: 0.1350, acc: 0.9263, test_acc: 0.7375, f1: 0.6042\n",
      "loss: 0.3085, acc: 0.9180, test_acc: 0.7330, f1: 0.6214\n",
      "loss: 0.2454, acc: 0.9167, test_acc: 0.7339, f1: 0.6066\n",
      "loss: 0.2395, acc: 0.9203, test_acc: 0.7277, f1: 0.5819\n",
      "loss: 0.2658, acc: 0.9148, test_acc: 0.7134, f1: 0.6010\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 9\n",
      "loss: 0.2195, acc: 0.9062, test_acc: 0.7330, f1: 0.5702\n",
      "loss: 0.1986, acc: 0.9219, test_acc: 0.7357, f1: 0.6141\n",
      "loss: 0.2077, acc: 0.9219, test_acc: 0.7438, f1: 0.6065\n",
      "loss: 0.2331, acc: 0.9141, test_acc: 0.7438, f1: 0.6094\n",
      "loss: 0.1728, acc: 0.9156, test_acc: 0.7348, f1: 0.6201\n",
      "loss: 0.1254, acc: 0.9219, test_acc: 0.7438, f1: 0.6101\n",
      "loss: 0.1503, acc: 0.9241, test_acc: 0.7259, f1: 0.6055\n",
      "loss: 0.1386, acc: 0.9277, test_acc: 0.7277, f1: 0.5921\n",
      "loss: 0.3091, acc: 0.9236, test_acc: 0.7393, f1: 0.6044\n",
      "loss: 0.1904, acc: 0.9250, test_acc: 0.7330, f1: 0.6139\n",
      "loss: 0.2755, acc: 0.9205, test_acc: 0.7482, f1: 0.6448\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7688\n",
      "loss: 0.0739, acc: 0.9217, test_acc: 0.7688, f1: 0.6499\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1931, acc: 0.9375, test_acc: 0.7580, f1: 0.6364\n",
      "loss: 0.1698, acc: 0.9453, test_acc: 0.7598, f1: 0.6450\n",
      "loss: 0.0787, acc: 0.9531, test_acc: 0.7607, f1: 0.6342\n",
      "loss: 0.0822, acc: 0.9570, test_acc: 0.7536, f1: 0.6240\n",
      "loss: 0.0526, acc: 0.9656, test_acc: 0.7482, f1: 0.6347\n",
      "loss: 0.1479, acc: 0.9609, test_acc: 0.7580, f1: 0.6423\n",
      "loss: 0.1523, acc: 0.9554, test_acc: 0.7554, f1: 0.6203\n",
      "loss: 0.1667, acc: 0.9531, test_acc: 0.7518, f1: 0.6303\n",
      "loss: 0.1054, acc: 0.9531, test_acc: 0.7268, f1: 0.6261\n",
      "loss: 0.2059, acc: 0.9500, test_acc: 0.7464, f1: 0.6152\n",
      "loss: 0.2988, acc: 0.9460, test_acc: 0.7446, f1: 0.5984\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 11\n",
      "loss: 0.1377, acc: 0.9844, test_acc: 0.7411, f1: 0.6329\n",
      "loss: 0.0771, acc: 0.9844, test_acc: 0.7366, f1: 0.6107\n",
      "loss: 0.0763, acc: 0.9740, test_acc: 0.7509, f1: 0.6210\n",
      "loss: 0.1150, acc: 0.9727, test_acc: 0.7527, f1: 0.6233\n",
      "loss: 0.1075, acc: 0.9688, test_acc: 0.7473, f1: 0.6362\n",
      "loss: 0.0590, acc: 0.9714, test_acc: 0.7562, f1: 0.6392\n",
      "loss: 0.0476, acc: 0.9754, test_acc: 0.7545, f1: 0.6298\n",
      "loss: 0.0573, acc: 0.9766, test_acc: 0.7500, f1: 0.6300\n",
      "loss: 0.0383, acc: 0.9792, test_acc: 0.7295, f1: 0.6183\n",
      "loss: 0.1047, acc: 0.9797, test_acc: 0.7482, f1: 0.6244\n",
      "loss: 0.0426, acc: 0.9815, test_acc: 0.7554, f1: 0.6254\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 12\n",
      "loss: 0.0637, acc: 0.9844, test_acc: 0.7509, f1: 0.6237\n",
      "loss: 0.0363, acc: 0.9922, test_acc: 0.7482, f1: 0.6305\n",
      "loss: 0.0968, acc: 0.9896, test_acc: 0.7446, f1: 0.6152\n",
      "loss: 0.0479, acc: 0.9922, test_acc: 0.7500, f1: 0.6227\n",
      "loss: 0.0277, acc: 0.9938, test_acc: 0.7491, f1: 0.6393\n",
      "loss: 0.0588, acc: 0.9896, test_acc: 0.7509, f1: 0.6403\n",
      "loss: 0.0764, acc: 0.9866, test_acc: 0.7536, f1: 0.6281\n",
      "loss: 0.0619, acc: 0.9844, test_acc: 0.7482, f1: 0.6231\n",
      "loss: 0.0946, acc: 0.9826, test_acc: 0.7357, f1: 0.6053\n",
      "loss: 0.0260, acc: 0.9844, test_acc: 0.7420, f1: 0.6174\n",
      "loss: 0.0928, acc: 0.9844, test_acc: 0.7321, f1: 0.6032\n",
      "loss: 0.0466, acc: 0.9844, test_acc: 0.7589, f1: 0.6461\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 13\n",
      "loss: 0.0858, acc: 0.9688, test_acc: 0.7518, f1: 0.6511\n",
      "loss: 0.0146, acc: 0.9844, test_acc: 0.7518, f1: 0.6445\n",
      "loss: 0.0108, acc: 0.9896, test_acc: 0.7545, f1: 0.6405\n",
      "loss: 0.0425, acc: 0.9883, test_acc: 0.7536, f1: 0.6245\n",
      "loss: 0.0457, acc: 0.9875, test_acc: 0.7491, f1: 0.6128\n",
      "loss: 0.0485, acc: 0.9870, test_acc: 0.7384, f1: 0.6155\n",
      "loss: 0.0652, acc: 0.9866, test_acc: 0.7500, f1: 0.6197\n",
      "loss: 0.0588, acc: 0.9844, test_acc: 0.7464, f1: 0.6154\n",
      "loss: 0.1821, acc: 0.9757, test_acc: 0.7482, f1: 0.6246\n",
      "loss: 0.0478, acc: 0.9766, test_acc: 0.7393, f1: 0.6101\n",
      "loss: 0.0128, acc: 0.9787, test_acc: 0.7536, f1: 0.6350\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 14\n",
      "loss: 0.0199, acc: 1.0000, test_acc: 0.7509, f1: 0.6302\n",
      "loss: 0.0681, acc: 0.9844, test_acc: 0.7420, f1: 0.6319\n",
      "loss: 0.0191, acc: 0.9844, test_acc: 0.7509, f1: 0.6319\n",
      "loss: 0.0122, acc: 0.9883, test_acc: 0.7348, f1: 0.5951\n",
      "loss: 0.0610, acc: 0.9875, test_acc: 0.7464, f1: 0.6090\n",
      "loss: 0.0107, acc: 0.9896, test_acc: 0.7411, f1: 0.6154\n",
      "loss: 0.0608, acc: 0.9911, test_acc: 0.7491, f1: 0.6293\n",
      "loss: 0.0557, acc: 0.9902, test_acc: 0.7571, f1: 0.6285\n",
      "loss: 0.0256, acc: 0.9896, test_acc: 0.7634, f1: 0.6431\n",
      "loss: 0.1356, acc: 0.9859, test_acc: 0.7536, f1: 0.6405\n",
      "loss: 0.0288, acc: 0.9872, test_acc: 0.7562, f1: 0.6448\n",
      "loss: 0.0644, acc: 0.9876, test_acc: 0.7357, f1: 0.6314\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 15\n",
      "loss: 0.0055, acc: 1.0000, test_acc: 0.7536, f1: 0.6292\n",
      "loss: 0.0743, acc: 0.9766, test_acc: 0.7455, f1: 0.6061\n",
      "loss: 0.0156, acc: 0.9844, test_acc: 0.7509, f1: 0.6232\n",
      "loss: 0.0604, acc: 0.9844, test_acc: 0.7509, f1: 0.6352\n",
      "loss: 0.0060, acc: 0.9875, test_acc: 0.7438, f1: 0.6192\n",
      "loss: 0.0466, acc: 0.9870, test_acc: 0.7473, f1: 0.6250\n",
      "loss: 0.0065, acc: 0.9888, test_acc: 0.7446, f1: 0.6247\n",
      "loss: 0.0496, acc: 0.9883, test_acc: 0.7482, f1: 0.6424\n",
      "loss: 0.0471, acc: 0.9878, test_acc: 0.7446, f1: 0.6395\n",
      "loss: 0.0168, acc: 0.9891, test_acc: 0.7491, f1: 0.6308\n",
      "loss: 0.0137, acc: 0.9901, test_acc: 0.7473, f1: 0.6189\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 16\n",
      "loss: 0.0342, acc: 1.0000, test_acc: 0.7482, f1: 0.6022\n",
      "loss: 0.0106, acc: 1.0000, test_acc: 0.7562, f1: 0.6353\n",
      "loss: 0.0140, acc: 1.0000, test_acc: 0.7491, f1: 0.6508\n",
      "loss: 0.0192, acc: 1.0000, test_acc: 0.7402, f1: 0.6419\n",
      "loss: 0.0122, acc: 1.0000, test_acc: 0.7446, f1: 0.6088\n",
      "loss: 0.0239, acc: 1.0000, test_acc: 0.7482, f1: 0.6020\n",
      "loss: 0.0262, acc: 0.9978, test_acc: 0.7545, f1: 0.6239\n",
      "loss: 0.0057, acc: 0.9980, test_acc: 0.7491, f1: 0.6395\n",
      "loss: 0.0107, acc: 0.9983, test_acc: 0.7509, f1: 0.6368\n",
      "loss: 0.0037, acc: 0.9984, test_acc: 0.7491, f1: 0.6231\n",
      "loss: 0.0410, acc: 0.9972, test_acc: 0.7491, f1: 0.6356\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 17\n",
      "loss: 0.0937, acc: 0.9688, test_acc: 0.7438, f1: 0.6374\n",
      "loss: 0.0275, acc: 0.9844, test_acc: 0.7429, f1: 0.6329\n",
      "loss: 0.0090, acc: 0.9896, test_acc: 0.7536, f1: 0.6315\n",
      "loss: 0.0359, acc: 0.9883, test_acc: 0.7491, f1: 0.6171\n",
      "loss: 0.0363, acc: 0.9844, test_acc: 0.7411, f1: 0.6378\n",
      "loss: 0.0349, acc: 0.9818, test_acc: 0.7420, f1: 0.6442\n",
      "loss: 0.0423, acc: 0.9821, test_acc: 0.7580, f1: 0.6454\n",
      "loss: 0.0352, acc: 0.9824, test_acc: 0.7482, f1: 0.6150\n",
      "loss: 0.0132, acc: 0.9844, test_acc: 0.7411, f1: 0.6103\n",
      "loss: 0.0251, acc: 0.9859, test_acc: 0.7438, f1: 0.6078\n",
      "loss: 0.0686, acc: 0.9858, test_acc: 0.7420, f1: 0.6074\n",
      "loss: 0.0960, acc: 0.9831, test_acc: 0.7473, f1: 0.6283\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 18\n",
      "loss: 0.0088, acc: 1.0000, test_acc: 0.7491, f1: 0.6350\n",
      "loss: 0.0441, acc: 0.9922, test_acc: 0.7384, f1: 0.6388\n",
      "loss: 0.0398, acc: 0.9896, test_acc: 0.7366, f1: 0.5986\n",
      "loss: 0.0194, acc: 0.9922, test_acc: 0.7375, f1: 0.6002\n",
      "loss: 0.0106, acc: 0.9938, test_acc: 0.7438, f1: 0.6028\n",
      "loss: 0.0345, acc: 0.9922, test_acc: 0.7420, f1: 0.6141\n",
      "loss: 0.0148, acc: 0.9933, test_acc: 0.7357, f1: 0.6120\n",
      "loss: 0.0120, acc: 0.9941, test_acc: 0.7429, f1: 0.6296\n",
      "loss: 0.0151, acc: 0.9948, test_acc: 0.7402, f1: 0.6016\n",
      "loss: 0.0271, acc: 0.9938, test_acc: 0.7518, f1: 0.6218\n",
      "loss: 0.0505, acc: 0.9929, test_acc: 0.7420, f1: 0.6305\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 19\n",
      "loss: 0.0170, acc: 1.0000, test_acc: 0.7330, f1: 0.6129\n",
      "loss: 0.0048, acc: 1.0000, test_acc: 0.7527, f1: 0.6175\n",
      "loss: 0.0714, acc: 0.9844, test_acc: 0.7482, f1: 0.6059\n",
      "loss: 0.0235, acc: 0.9844, test_acc: 0.7357, f1: 0.6034\n",
      "loss: 0.0347, acc: 0.9844, test_acc: 0.7339, f1: 0.6217\n",
      "loss: 0.0293, acc: 0.9844, test_acc: 0.7455, f1: 0.6281\n",
      "loss: 0.0916, acc: 0.9844, test_acc: 0.7464, f1: 0.6285\n",
      "loss: 0.0186, acc: 0.9863, test_acc: 0.7616, f1: 0.6432\n",
      "loss: 0.0788, acc: 0.9844, test_acc: 0.7536, f1: 0.6261\n",
      "loss: 0.0953, acc: 0.9844, test_acc: 0.7527, f1: 0.6250\n",
      "loss: 0.1566, acc: 0.9801, test_acc: 0.7411, f1: 0.6169\n",
      "loss: 0.0121, acc: 0.9808, test_acc: 0.7411, f1: 0.6318\n",
      "max_test_acc: 0.76875, max_f1: 0.6518495525565207\n",
      "##################################################\n",
      "max_test_acc_overall: 0.76875\n",
      "max_f1_overall: 0.6518495525565207\n"
     ]
    }
   ],
   "source": [
    "run(model_AE , writer_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca70496a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = torch.tensor(tokenizer.text_to_sequence(\"MS Office 2011 for Mac is wonderful, well worth it.\")).reshape(1,-1)\n",
    "sample_aspect = torch.tensor(tokenizer.text_to_sequence('MS Office 2011 for Mac').reshape(1,-1))\n",
    "data = [sample_data, sample_aspect]\n",
    "output = model_AE(data)\n",
    "polarity_dict[int(torch.argmax(output, -1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea3826bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 80\n",
    "position_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "666b171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cc0a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBAN(nn.Module):\n",
    "    ''' Position-aware bidirectional attention network '''\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super(PBAN, self).__init__()\n",
    "        self.text_embed = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float))\n",
    "        self.pos_embed = nn.Embedding(max_length, position_dim)\n",
    "        self.left_gru = DynamicLSTM(embed_dim, hidden_dim, num_layers=1, \n",
    "                                    batch_first=True, bidirectional=True, rnn_type='GRU')\n",
    "        self.right_gru = DynamicLSTM(embed_dim+position_dim, hidden_dim, num_layers=1, \n",
    "                                     batch_first=True, bidirectional=True, rnn_type='GRU')\n",
    "        self.weight_m = nn.Parameter(torch.Tensor(hidden_dim*2, hidden_dim*2))\n",
    "        self.bias_m = nn.Parameter(torch.Tensor(1))\n",
    "        self.weight_n = nn.Parameter(torch.Tensor(hidden_dim*2, hidden_dim*2))\n",
    "        self.bias_n = nn.Parameter(torch.Tensor(1))\n",
    "        self.w_r = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.w_s = nn.Linear(hidden_dim, polarities_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        text, aspect_text, position_tag = inputs[0], inputs[1], inputs[2]\n",
    "        ''' Sentence representation '''\n",
    "        x = self.text_embed(text)\n",
    "        position = self.pos_embed(position_tag)\n",
    "        x_len = torch.sum(text != 0, dim=-1)\n",
    "        x = torch.cat((position, x), dim=-1)\n",
    "        h_x, _ = self.right_gru(x, x_len)\n",
    "        ''' Aspect term representation '''\n",
    "        aspect = self.text_embed(aspect_text)\n",
    "        aspect_len = torch.sum(aspect_text != 0, dim=-1)\n",
    "        h_t, _ = self.left_gru(aspect, aspect_len)\n",
    "        ''' Aspect term to position-aware sentence attention '''\n",
    "        alpha = F.softmax(torch.tanh(torch.add(torch.bmm(torch.matmul(h_t, self.weight_m), torch.transpose(h_x, 1, 2)), self.bias_m)), dim=1)\n",
    "        s_x = torch.bmm(alpha, h_x)\n",
    "        ''' Position-aware sentence attention to aspect term '''\n",
    "        h_x_pool = torch.unsqueeze(torch.div(torch.sum(h_x, dim=1), x_len.float().view(x_len.size(0), 1)), dim=1)\n",
    "        gamma = F.softmax(torch.tanh(torch.add(torch.bmm(torch.matmul(h_x_pool, self.weight_n), torch.transpose(h_t, 1, 2)), self.bias_n)), dim=1)\n",
    "        h_r = torch.squeeze(torch.bmm(gamma, s_x), dim=1)\n",
    "        ''' Output transform '''\n",
    "        out = torch.tanh(self.w_r(h_r))\n",
    "        out = self.w_s(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "906353d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PBAN = PBAN(embedding_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57fc657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PBAN(\n",
       "  (text_embed): Embedding(4445, 200)\n",
       "  (pos_embed): Embedding(80, 100)\n",
       "  (left_gru): DynamicLSTM(\n",
       "    (RNN): GRU(200, 200, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (right_gru): DynamicLSTM(\n",
       "    (RNN): GRU(300, 200, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (w_r): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (w_s): Linear(in_features=200, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_PBAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d754fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "lr=0.001\n",
    "l2_reg=1e-5\n",
    "num_epoch = 20\n",
    "input_cols = ['text', 'aspect', 'position']\n",
    "log_step = 5\n",
    "model_name = 'pban_lstm'\n",
    "dataset = 'restaurant'\n",
    "batch_size = 64\n",
    "embed_dim = 200\n",
    "hidden_dim = 200\n",
    "polarities_dim = 3\n",
    "polarity_dict = {0: 'positive', 1: 'negative', 2:'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "027aa76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "params = filter(lambda p: p.requires_grad, model_PBAN.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=lr, weight_decay=l2_reg)\n",
    "writer_PBAN = SummaryWriter(f\"runs/PBAN_LSTM/BatchSize {batch_size} LR {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "409fb865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat: 0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 0\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6500\n",
      "loss: 1.1307, acc: 0.5469, test_acc: 0.6500, f1: 0.2691\n",
      "loss: 0.8421, acc: 0.5938, test_acc: 0.6500, f1: 0.2626\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6562\n",
      "loss: 1.0627, acc: 0.5469, test_acc: 0.6562, f1: 0.2867\n",
      "loss: 0.8875, acc: 0.5586, test_acc: 0.6500, f1: 0.2626\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6759\n",
      "loss: 0.8043, acc: 0.5875, test_acc: 0.6759, f1: 0.3940\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.6920\n",
      "loss: 0.8958, acc: 0.5781, test_acc: 0.6920, f1: 0.4041\n",
      "loss: 0.8117, acc: 0.5848, test_acc: 0.6696, f1: 0.3415\n",
      "loss: 0.9652, acc: 0.5801, test_acc: 0.6830, f1: 0.3817\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7036\n",
      "loss: 0.7061, acc: 0.5938, test_acc: 0.7036, f1: 0.4427\n",
      "loss: 0.6050, acc: 0.6094, test_acc: 0.7027, f1: 0.4424\n",
      "loss: 0.6967, acc: 0.6222, test_acc: 0.6991, f1: 0.4672\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 1\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7098\n",
      "loss: 0.7670, acc: 0.6406, test_acc: 0.7098, f1: 0.4639\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7143\n",
      "loss: 0.7449, acc: 0.6562, test_acc: 0.7143, f1: 0.4724\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7214\n",
      "loss: 0.6991, acc: 0.6615, test_acc: 0.7214, f1: 0.5552\n",
      "loss: 0.5342, acc: 0.6836, test_acc: 0.7009, f1: 0.4557\n",
      "loss: 0.7159, acc: 0.6937, test_acc: 0.7161, f1: 0.4771\n",
      "loss: 0.7602, acc: 0.6927, test_acc: 0.7125, f1: 0.5808\n",
      "loss: 0.6088, acc: 0.6964, test_acc: 0.7080, f1: 0.4692\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7259\n",
      "loss: 0.7157, acc: 0.6973, test_acc: 0.7259, f1: 0.6031\n",
      "loss: 0.6583, acc: 0.6997, test_acc: 0.7250, f1: 0.5136\n",
      "loss: 0.7494, acc: 0.6969, test_acc: 0.7063, f1: 0.4840\n",
      "loss: 0.5285, acc: 0.7102, test_acc: 0.7196, f1: 0.5257\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 2\n",
      "loss: 0.6328, acc: 0.7344, test_acc: 0.7161, f1: 0.4837\n",
      "loss: 0.7843, acc: 0.7109, test_acc: 0.7250, f1: 0.5639\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7312\n",
      "loss: 0.6261, acc: 0.7188, test_acc: 0.7312, f1: 0.5394\n",
      "loss: 0.7941, acc: 0.6875, test_acc: 0.7250, f1: 0.5867\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7384\n",
      "loss: 0.6745, acc: 0.6844, test_acc: 0.7384, f1: 0.5711\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7518\n",
      "loss: 0.6514, acc: 0.6901, test_acc: 0.7518, f1: 0.6362\n",
      "loss: 0.6069, acc: 0.7009, test_acc: 0.7429, f1: 0.5778\n",
      "loss: 0.7814, acc: 0.6953, test_acc: 0.7455, f1: 0.5860\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7580\n",
      "loss: 0.7042, acc: 0.6910, test_acc: 0.7580, f1: 0.6288\n",
      "loss: 0.7452, acc: 0.6875, test_acc: 0.7491, f1: 0.6020\n",
      "loss: 0.7093, acc: 0.6946, test_acc: 0.7429, f1: 0.5807\n",
      "loss: 0.6740, acc: 0.6927, test_acc: 0.7411, f1: 0.5903\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 3\n",
      "loss: 0.6440, acc: 0.7031, test_acc: 0.7455, f1: 0.5858\n",
      "loss: 0.5204, acc: 0.7500, test_acc: 0.7545, f1: 0.5979\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7589\n",
      "loss: 0.5854, acc: 0.7552, test_acc: 0.7589, f1: 0.6539\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7688\n",
      "loss: 0.5118, acc: 0.7656, test_acc: 0.7688, f1: 0.6466\n",
      "loss: 0.5832, acc: 0.7750, test_acc: 0.7580, f1: 0.6107\n",
      "loss: 0.6783, acc: 0.7474, test_acc: 0.7527, f1: 0.6435\n",
      "loss: 0.6771, acc: 0.7455, test_acc: 0.7339, f1: 0.5322\n",
      "loss: 0.6900, acc: 0.7461, test_acc: 0.7625, f1: 0.6262\n",
      "loss: 0.7994, acc: 0.7396, test_acc: 0.7562, f1: 0.6152\n",
      "loss: 0.7011, acc: 0.7375, test_acc: 0.7545, f1: 0.6360\n",
      "loss: 0.6287, acc: 0.7386, test_acc: 0.7205, f1: 0.4920\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 4\n",
      "loss: 0.7631, acc: 0.5938, test_acc: 0.7286, f1: 0.6024\n",
      "loss: 0.5559, acc: 0.6641, test_acc: 0.7223, f1: 0.5156\n",
      "loss: 0.7995, acc: 0.6615, test_acc: 0.7536, f1: 0.6280\n",
      "loss: 0.5512, acc: 0.6875, test_acc: 0.7518, f1: 0.5991\n",
      "loss: 0.6715, acc: 0.6906, test_acc: 0.7438, f1: 0.5756\n",
      "loss: 0.6550, acc: 0.6979, test_acc: 0.7188, f1: 0.6128\n",
      "loss: 0.5508, acc: 0.7054, test_acc: 0.7366, f1: 0.5744\n",
      "loss: 0.7833, acc: 0.6973, test_acc: 0.7330, f1: 0.5689\n",
      "loss: 0.5779, acc: 0.7049, test_acc: 0.7518, f1: 0.6425\n",
      "loss: 0.4615, acc: 0.7125, test_acc: 0.7491, f1: 0.5872\n",
      "loss: 0.6214, acc: 0.7102, test_acc: 0.7411, f1: 0.5755\n",
      "loss: 0.4629, acc: 0.7115, test_acc: 0.7536, f1: 0.6245\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 5\n",
      "loss: 0.4997, acc: 0.7812, test_acc: 0.7429, f1: 0.5867\n",
      "loss: 0.7064, acc: 0.7344, test_acc: 0.7420, f1: 0.5682\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7705\n",
      "loss: 0.5055, acc: 0.7500, test_acc: 0.7705, f1: 0.6463\n",
      "loss: 0.3553, acc: 0.7773, test_acc: 0.7634, f1: 0.6147\n",
      "loss: 0.4271, acc: 0.7969, test_acc: 0.7455, f1: 0.6369\n",
      "loss: 0.3915, acc: 0.8099, test_acc: 0.7580, f1: 0.6269\n",
      "loss: 0.5128, acc: 0.8080, test_acc: 0.7696, f1: 0.6389\n",
      "loss: 0.7204, acc: 0.7910, test_acc: 0.7679, f1: 0.6566\n",
      "loss: 0.4531, acc: 0.7917, test_acc: 0.7455, f1: 0.5681\n",
      "loss: 0.5486, acc: 0.7859, test_acc: 0.7616, f1: 0.6488\n",
      "loss: 0.5562, acc: 0.7855, test_acc: 0.7670, f1: 0.6238\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 6\n",
      "loss: 0.6291, acc: 0.7500, test_acc: 0.7509, f1: 0.6142\n",
      "loss: 0.5543, acc: 0.7656, test_acc: 0.7304, f1: 0.5489\n",
      "loss: 0.4000, acc: 0.7969, test_acc: 0.7464, f1: 0.5957\n",
      "loss: 0.4640, acc: 0.7930, test_acc: 0.7580, f1: 0.6046\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7732\n",
      "loss: 0.5078, acc: 0.7781, test_acc: 0.7732, f1: 0.6549\n",
      "loss: 0.5092, acc: 0.7865, test_acc: 0.7696, f1: 0.6464\n",
      "loss: 0.5474, acc: 0.7835, test_acc: 0.7384, f1: 0.6275\n",
      "loss: 0.5524, acc: 0.7734, test_acc: 0.7616, f1: 0.6240\n",
      "loss: 0.4593, acc: 0.7847, test_acc: 0.7482, f1: 0.5632\n",
      "loss: 0.5153, acc: 0.7859, test_acc: 0.7696, f1: 0.6443\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7804\n",
      "loss: 0.5155, acc: 0.7841, test_acc: 0.7804, f1: 0.6536\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 7\n",
      "loss: 0.5590, acc: 0.7656, test_acc: 0.7795, f1: 0.6641\n",
      "loss: 0.4780, acc: 0.7578, test_acc: 0.7625, f1: 0.5843\n",
      "loss: 0.6537, acc: 0.7552, test_acc: 0.7304, f1: 0.4978\n",
      "loss: 0.5099, acc: 0.7656, test_acc: 0.7545, f1: 0.6178\n",
      "loss: 0.5218, acc: 0.7750, test_acc: 0.7616, f1: 0.6316\n",
      "loss: 0.4348, acc: 0.7839, test_acc: 0.7616, f1: 0.6401\n",
      "loss: 0.5100, acc: 0.7879, test_acc: 0.7598, f1: 0.6098\n",
      "loss: 0.5244, acc: 0.7910, test_acc: 0.7723, f1: 0.6519\n",
      "loss: 0.5962, acc: 0.7830, test_acc: 0.7705, f1: 0.6544\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7812\n",
      "loss: 0.6277, acc: 0.7812, test_acc: 0.7812, f1: 0.6794\n",
      "loss: 0.5278, acc: 0.7727, test_acc: 0.7732, f1: 0.6646\n",
      "loss: 0.4040, acc: 0.7773, test_acc: 0.7812, f1: 0.6596\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 8\n",
      "loss: 0.5677, acc: 0.7656, test_acc: 0.7750, f1: 0.6458\n",
      "loss: 0.3651, acc: 0.8203, test_acc: 0.7670, f1: 0.6370\n",
      "loss: 0.4126, acc: 0.8333, test_acc: 0.7598, f1: 0.6540\n",
      "loss: 0.4575, acc: 0.8242, test_acc: 0.7625, f1: 0.6185\n",
      "loss: 0.3141, acc: 0.8375, test_acc: 0.7732, f1: 0.6692\n",
      "loss: 0.3858, acc: 0.8359, test_acc: 0.7616, f1: 0.6121\n",
      "loss: 0.5285, acc: 0.8281, test_acc: 0.7554, f1: 0.6770\n",
      "loss: 0.3930, acc: 0.8281, test_acc: 0.7634, f1: 0.6179\n",
      "loss: 0.4215, acc: 0.8299, test_acc: 0.7679, f1: 0.6533\n",
      "loss: 0.4794, acc: 0.8266, test_acc: 0.7714, f1: 0.6647\n",
      "loss: 0.5915, acc: 0.8253, test_acc: 0.7714, f1: 0.6445\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 9\n",
      "loss: 0.3822, acc: 0.8906, test_acc: 0.7571, f1: 0.6016\n",
      "loss: 0.3172, acc: 0.8828, test_acc: 0.7634, f1: 0.6631\n",
      "loss: 0.4197, acc: 0.8542, test_acc: 0.7768, f1: 0.6750\n",
      "loss: 0.4195, acc: 0.8477, test_acc: 0.7759, f1: 0.6699\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7830\n",
      "loss: 0.4628, acc: 0.8375, test_acc: 0.7830, f1: 0.6847\n",
      "loss: 0.2774, acc: 0.8438, test_acc: 0.7795, f1: 0.6656\n",
      "loss: 0.5691, acc: 0.8281, test_acc: 0.7661, f1: 0.6471\n",
      "loss: 0.3594, acc: 0.8340, test_acc: 0.7625, f1: 0.6189\n",
      "loss: 0.2787, acc: 0.8420, test_acc: 0.7786, f1: 0.6849\n",
      "loss: 0.3196, acc: 0.8469, test_acc: 0.7634, f1: 0.6101\n",
      "loss: 0.4425, acc: 0.8480, test_acc: 0.7625, f1: 0.6700\n",
      "loss: 0.4705, acc: 0.8434, test_acc: 0.7750, f1: 0.6495\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2652, acc: 0.9062, test_acc: 0.7634, f1: 0.6302\n",
      "loss: 0.3887, acc: 0.8906, test_acc: 0.7812, f1: 0.6654\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7839\n",
      "loss: 0.2881, acc: 0.8958, test_acc: 0.7839, f1: 0.6728\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7857\n",
      "loss: 0.5305, acc: 0.8711, test_acc: 0.7857, f1: 0.6772\n",
      "loss: 0.3146, acc: 0.8719, test_acc: 0.7688, f1: 0.6405\n",
      "loss: 0.3242, acc: 0.8698, test_acc: 0.7786, f1: 0.6690\n",
      "loss: 0.4808, acc: 0.8571, test_acc: 0.7616, f1: 0.6273\n",
      "loss: 0.4441, acc: 0.8516, test_acc: 0.7688, f1: 0.6523\n",
      "loss: 0.4525, acc: 0.8472, test_acc: 0.7839, f1: 0.6766\n",
      "loss: 0.3154, acc: 0.8500, test_acc: 0.7821, f1: 0.6717\n",
      "loss: 0.3845, acc: 0.8509, test_acc: 0.7759, f1: 0.6641\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 11\n",
      "loss: 0.2400, acc: 0.8750, test_acc: 0.7741, f1: 0.6663\n",
      "loss: 0.3753, acc: 0.8750, test_acc: 0.7616, f1: 0.6425\n",
      "loss: 0.5164, acc: 0.8646, test_acc: 0.7616, f1: 0.6319\n",
      "loss: 0.3767, acc: 0.8594, test_acc: 0.7259, f1: 0.6118\n",
      "loss: 0.2332, acc: 0.8688, test_acc: 0.7500, f1: 0.5651\n",
      "loss: 0.3855, acc: 0.8620, test_acc: 0.7509, f1: 0.6171\n",
      "loss: 0.3211, acc: 0.8683, test_acc: 0.7554, f1: 0.6264\n",
      "loss: 0.3645, acc: 0.8633, test_acc: 0.7750, f1: 0.6777\n",
      "loss: 0.5027, acc: 0.8490, test_acc: 0.7741, f1: 0.6538\n",
      "loss: 0.3509, acc: 0.8531, test_acc: 0.7705, f1: 0.6532\n",
      "loss: 0.3775, acc: 0.8551, test_acc: 0.7804, f1: 0.6710\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 12\n",
      "loss: 0.3075, acc: 0.8750, test_acc: 0.7812, f1: 0.6756\n",
      "loss: 0.2486, acc: 0.8750, test_acc: 0.7777, f1: 0.6643\n",
      "loss: 0.4357, acc: 0.8594, test_acc: 0.7830, f1: 0.6764\n",
      "loss: 0.3353, acc: 0.8516, test_acc: 0.7750, f1: 0.6463\n",
      "loss: 0.3584, acc: 0.8500, test_acc: 0.7795, f1: 0.6689\n",
      "loss: 0.2289, acc: 0.8620, test_acc: 0.7759, f1: 0.6592\n",
      "loss: 0.2095, acc: 0.8683, test_acc: 0.7741, f1: 0.6683\n",
      "loss: 0.1682, acc: 0.8809, test_acc: 0.7616, f1: 0.6166\n",
      "loss: 0.2622, acc: 0.8837, test_acc: 0.7679, f1: 0.6580\n",
      "loss: 0.1509, acc: 0.8922, test_acc: 0.7786, f1: 0.6703\n",
      "loss: 0.4775, acc: 0.8849, test_acc: 0.7723, f1: 0.6475\n",
      "loss: 0.4227, acc: 0.8802, test_acc: 0.7625, f1: 0.6332\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 13\n",
      "loss: 0.2179, acc: 0.9219, test_acc: 0.7759, f1: 0.6668\n",
      "loss: 0.3455, acc: 0.8906, test_acc: 0.7759, f1: 0.6796\n",
      "loss: 0.1229, acc: 0.9167, test_acc: 0.7768, f1: 0.6725\n",
      "loss: 0.2073, acc: 0.9062, test_acc: 0.7759, f1: 0.6668\n",
      "loss: 0.2958, acc: 0.9031, test_acc: 0.7812, f1: 0.6832\n",
      "loss: 0.4780, acc: 0.8932, test_acc: 0.7723, f1: 0.6476\n",
      "loss: 0.5535, acc: 0.8795, test_acc: 0.7134, f1: 0.6440\n",
      "loss: 0.6450, acc: 0.8652, test_acc: 0.7536, f1: 0.5924\n",
      "loss: 0.2883, acc: 0.8681, test_acc: 0.7518, f1: 0.6487\n",
      "loss: 0.2874, acc: 0.8703, test_acc: 0.7571, f1: 0.6019\n",
      "loss: 0.1698, acc: 0.8736, test_acc: 0.7723, f1: 0.6821\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 14\n",
      "loss: 0.2086, acc: 0.9062, test_acc: 0.7795, f1: 0.6861\n",
      "loss: 0.1988, acc: 0.9297, test_acc: 0.7741, f1: 0.6655\n",
      "loss: 0.1966, acc: 0.9271, test_acc: 0.7839, f1: 0.6851\n",
      "loss: 0.3553, acc: 0.9023, test_acc: 0.7652, f1: 0.6153\n",
      "loss: 0.4036, acc: 0.8906, test_acc: 0.7795, f1: 0.6701\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7902\n",
      "loss: 0.2549, acc: 0.8932, test_acc: 0.7902, f1: 0.6930\n",
      "loss: 0.2858, acc: 0.8817, test_acc: 0.7786, f1: 0.6611\n",
      "loss: 0.2444, acc: 0.8809, test_acc: 0.7696, f1: 0.6800\n",
      "loss: 0.3261, acc: 0.8785, test_acc: 0.7768, f1: 0.6763\n",
      "loss: 0.2312, acc: 0.8828, test_acc: 0.7679, f1: 0.6578\n",
      "loss: 0.3269, acc: 0.8821, test_acc: 0.7634, f1: 0.6538\n",
      "loss: 0.3343, acc: 0.8805, test_acc: 0.7679, f1: 0.6753\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 15\n",
      "model saved: ./state_dict/LSTM_restaurant_3class_acc0.7920\n",
      "loss: 0.1901, acc: 0.9531, test_acc: 0.7920, f1: 0.6895\n",
      "loss: 0.1817, acc: 0.9453, test_acc: 0.7821, f1: 0.6676\n",
      "loss: 0.1820, acc: 0.9323, test_acc: 0.7875, f1: 0.6953\n",
      "loss: 0.2730, acc: 0.9219, test_acc: 0.7893, f1: 0.7077\n",
      "loss: 0.1996, acc: 0.9250, test_acc: 0.7804, f1: 0.6611\n",
      "loss: 0.2008, acc: 0.9297, test_acc: 0.7768, f1: 0.6864\n",
      "loss: 0.2054, acc: 0.9353, test_acc: 0.7795, f1: 0.6848\n",
      "loss: 0.1473, acc: 0.9375, test_acc: 0.7750, f1: 0.6644\n",
      "loss: 0.1726, acc: 0.9358, test_acc: 0.7866, f1: 0.6892\n",
      "loss: 0.1905, acc: 0.9344, test_acc: 0.7830, f1: 0.6761\n",
      "loss: 0.2448, acc: 0.9332, test_acc: 0.7598, f1: 0.6569\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 16\n",
      "loss: 0.2066, acc: 0.9062, test_acc: 0.7768, f1: 0.6593\n",
      "loss: 0.1443, acc: 0.9219, test_acc: 0.7705, f1: 0.6586\n",
      "loss: 0.1259, acc: 0.9375, test_acc: 0.7670, f1: 0.6617\n",
      "loss: 0.1972, acc: 0.9453, test_acc: 0.7750, f1: 0.6834\n",
      "loss: 0.0776, acc: 0.9531, test_acc: 0.7696, f1: 0.6519\n",
      "loss: 0.1391, acc: 0.9531, test_acc: 0.7723, f1: 0.6802\n",
      "loss: 0.1413, acc: 0.9509, test_acc: 0.7830, f1: 0.6876\n",
      "loss: 0.2550, acc: 0.9414, test_acc: 0.7607, f1: 0.6281\n",
      "loss: 0.0894, acc: 0.9479, test_acc: 0.7750, f1: 0.6796\n",
      "loss: 0.1762, acc: 0.9453, test_acc: 0.7741, f1: 0.6746\n",
      "loss: 0.1241, acc: 0.9446, test_acc: 0.7705, f1: 0.6418\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 17\n",
      "loss: 0.0695, acc: 0.9688, test_acc: 0.7652, f1: 0.6674\n",
      "loss: 0.1359, acc: 0.9609, test_acc: 0.7688, f1: 0.6588\n",
      "loss: 0.0406, acc: 0.9740, test_acc: 0.7607, f1: 0.6209\n",
      "loss: 0.0910, acc: 0.9727, test_acc: 0.7643, f1: 0.6545\n",
      "loss: 0.2458, acc: 0.9594, test_acc: 0.7777, f1: 0.6668\n",
      "loss: 0.0890, acc: 0.9609, test_acc: 0.7741, f1: 0.6656\n",
      "loss: 0.1061, acc: 0.9598, test_acc: 0.7679, f1: 0.6773\n",
      "loss: 0.0894, acc: 0.9629, test_acc: 0.7723, f1: 0.6450\n",
      "loss: 0.0614, acc: 0.9653, test_acc: 0.7768, f1: 0.6550\n",
      "loss: 0.0548, acc: 0.9688, test_acc: 0.7661, f1: 0.6630\n",
      "loss: 0.0634, acc: 0.9702, test_acc: 0.7634, f1: 0.6431\n",
      "loss: 0.2352, acc: 0.9688, test_acc: 0.7661, f1: 0.6652\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 18\n",
      "loss: 0.0585, acc: 0.9844, test_acc: 0.7696, f1: 0.6649\n",
      "loss: 0.0339, acc: 0.9922, test_acc: 0.7696, f1: 0.6535\n",
      "loss: 0.0938, acc: 0.9792, test_acc: 0.7670, f1: 0.6567\n",
      "loss: 0.0391, acc: 0.9844, test_acc: 0.7777, f1: 0.6742\n",
      "loss: 0.0745, acc: 0.9812, test_acc: 0.7795, f1: 0.6664\n",
      "loss: 0.1090, acc: 0.9766, test_acc: 0.7670, f1: 0.6426\n",
      "loss: 0.0977, acc: 0.9754, test_acc: 0.7688, f1: 0.6866\n",
      "loss: 0.0720, acc: 0.9766, test_acc: 0.7714, f1: 0.6639\n",
      "loss: 0.1461, acc: 0.9740, test_acc: 0.7750, f1: 0.6692\n",
      "loss: 0.1573, acc: 0.9703, test_acc: 0.7723, f1: 0.6651\n",
      "loss: 0.0516, acc: 0.9716, test_acc: 0.7634, f1: 0.6379\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 19\n",
      "loss: 0.1730, acc: 0.9375, test_acc: 0.7670, f1: 0.6457\n",
      "loss: 0.0256, acc: 0.9688, test_acc: 0.7679, f1: 0.6577\n",
      "loss: 0.0721, acc: 0.9740, test_acc: 0.7509, f1: 0.6266\n",
      "loss: 0.0366, acc: 0.9766, test_acc: 0.7634, f1: 0.6391\n",
      "loss: 0.0656, acc: 0.9781, test_acc: 0.7705, f1: 0.6518\n",
      "loss: 0.0319, acc: 0.9818, test_acc: 0.7661, f1: 0.6417\n",
      "loss: 0.1121, acc: 0.9799, test_acc: 0.7768, f1: 0.6702\n",
      "loss: 0.0510, acc: 0.9805, test_acc: 0.7812, f1: 0.6716\n",
      "loss: 0.1010, acc: 0.9792, test_acc: 0.7812, f1: 0.6710\n",
      "loss: 0.0549, acc: 0.9797, test_acc: 0.7634, f1: 0.6607\n",
      "loss: 0.1361, acc: 0.9787, test_acc: 0.7679, f1: 0.6553\n",
      "loss: 0.1279, acc: 0.9766, test_acc: 0.7652, f1: 0.6514\n",
      "max_test_acc: 0.7919642857142857, max_f1: 0.7077251847773572\n",
      "##################################################\n",
      "max_test_acc_overall: 0.7919642857142857\n",
      "max_f1_overall: 0.7077251847773572\n"
     ]
    }
   ],
   "source": [
    "run(model_PBAN , writer_PBAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513aa81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75056d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629d3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
