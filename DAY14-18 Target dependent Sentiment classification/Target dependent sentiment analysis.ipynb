{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33412c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_utils import build_tokenizer, build_embedding_matrix, SentenceDataset,Tokenizer, Vocab\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de04e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe09519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: datasets/restaurant_tokenizer.dat\n",
      "loading embedding matrix: datasets/200d_restaurant_embedding_matrix.dat\n"
     ]
    }
   ],
   "source": [
    "data_files = ['../data/td_lstm_datasets/Laptops_Train.xml', '../data/td_lstm_datasets/Laptops_Train.xml']\n",
    "tokenizer = build_tokenizer(\n",
    "    fnames=data_files,\n",
    "    max_length=80,\n",
    "    data_file='datasets/{0}_tokenizer.dat'.format('restaurant'))\n",
    "embedding_matrix = build_embedding_matrix(\n",
    "    vocab=tokenizer.vocab,\n",
    "    embed_dim=200,\n",
    "    data_file='datasets/{0}d_{1}_embedding_matrix.dat'.format('200', 'restaurant'))\n",
    "trainset = SentenceDataset(data_files[0] , tokenizer, target_dim=3)\n",
    "testset = SentenceDataset(data_files[1] , tokenizer, target_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b46ec346",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "embed_dim = 200\n",
    "hidden_dim = 200\n",
    "polarities_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06815f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53cdffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicLSTM(nn.Module):\n",
    "    '''\n",
    "    LSTM which can hold variable length sequence, use like TensorFlow's RNN(input, lenght...).\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, batch_first=True, dropout=0,\n",
    "                 bidirectional=False, only_use_last_hidden_state=False, rnn_type='LSTM'):\n",
    "        super(DynamicLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.batch_first = batch_first\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.only_use_last_hidden_state = only_use_last_hidden_state\n",
    "        self.rnn_type = rnn_type\n",
    "        \n",
    "        if self.rnn_type == 'LSTM':\n",
    "            self.RNN = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                               bias=bias, batch_first=batch_first, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif self.rnn_type == 'GRU':\n",
    "            self.RNN = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                              bias=bias, batch_first=batch_first, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif self.rnn_type == 'RNN':\n",
    "            self.RNN = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                              bias=bias, batch_first=batch_first, dropout=dropout, bidirectional=bidirectional)\n",
    "    \n",
    "    def forward(self, x, x_len):\n",
    "        '''\n",
    "        sequence -> sort -> pad and pack -> process using RNN -> unpack -> unsort\n",
    "        '''\n",
    "        '''sort'''\n",
    "        x_sort_idx = torch.sort(x_len, descending=True)[1].long()\n",
    "        x_unsort_idx = torch.sort(x_sort_idx)[1].long()\n",
    "        x_len = x_len[x_sort_idx]\n",
    "        x = x[x_sort_idx]\n",
    "        '''pack'''\n",
    "        x_emb_p = torch.nn.utils.rnn.pack_padded_sequence(x, x_len, batch_first=self.batch_first)\n",
    "        ''' process '''\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            out_pack, (ht, ct) = self.RNN(x_emb_p, None)\n",
    "        else:\n",
    "            out_pack, ht = self.RNN(x_emb_p, None)\n",
    "            ct = None\n",
    "        '''unsort'''\n",
    "        ht = ht[:, x_unsort_idx]\n",
    "        if self.only_use_last_hidden_state:\n",
    "            return ht\n",
    "        else:\n",
    "            out, _ = torch.nn.utils.rnn.pad_packed_sequence(out_pack, batch_first=self.batch_first)\n",
    "            if self.batch_first:\n",
    "                out = out[x_unsort_idx]\n",
    "            else:\n",
    "                out = out[:, x_unsort_idx]\n",
    "            if self.rnn_type == 'LSTM':\n",
    "                ct = ct[:, x_unsort_idx]\n",
    "            return out, (ht, ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75949fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    ''' Standard LSTM '''\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embed = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float))\n",
    "        self.lstm = DynamicLSTM(embed_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_dim, polarities_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        text = inputs[0]\n",
    "        x = self.embed(text)\n",
    "        x_len = torch.sum(text != 0, dim=-1)\n",
    "        _, (h_n, _) = self.lstm(x, x_len)\n",
    "        out = self.dense(h_n[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "968fb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(embedding_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "482bc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params():\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            if len(p.shape) > 1:\n",
    "                torch.nn.init.xavier_normal_(p)\n",
    "            else:\n",
    "                stdv = 1. / (p.shape[0]**0.5)\n",
    "                torch.nn.init.uniform_(p, a=-stdv, b=stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0681ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trainable_params: 322203, n_nontrainable_params: 627200\n"
     ]
    }
   ],
   "source": [
    "n_trainable_params, n_nontrainable_params = 0, 0\n",
    "for p in model.parameters():\n",
    "    n_params = torch.prod(torch.tensor(p.shape))\n",
    "    if p.requires_grad:\n",
    "        n_trainable_params += n_params\n",
    "    else:\n",
    "        n_nontrainable_params += n_params\n",
    "print('n_trainable_params: {0}, n_nontrainable_params: {1}'.format(n_trainable_params, n_nontrainable_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2c191be",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "lr=0.001\n",
    "l2_reg=1e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=lr, weight_decay=l2_reg)\n",
    "num_epoch = 20\n",
    "input_cols = ['text']\n",
    "log_step = 5\n",
    "model_name = 'pban'\n",
    "dataset = 'restaurant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09e4df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(criterion, optimizer, max_test_acc_overall=0):\n",
    "    max_test_acc = 0\n",
    "    max_f1 = 0\n",
    "    global_step = 0\n",
    "    for epoch in range(num_epoch):\n",
    "        print('>' * 50)\n",
    "        print('epoch:', epoch)\n",
    "        n_correct, n_total = 0, 0\n",
    "        for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "            global_step += 1\n",
    "            # switch model to training mode, clear gradient accumulators\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = [sample_batched[col].to(device) for col in input_cols]\n",
    "            outputs = model(inputs)\n",
    "            targets = sample_batched['polarity'].to(device)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if global_step % log_step == 0:\n",
    "                n_correct += (torch.argmax(outputs, -1) == targets).sum().item()\n",
    "                n_total += len(outputs)\n",
    "                train_acc = n_correct / n_total\n",
    "                test_acc, f1 = evaluate()\n",
    "                if test_acc > max_test_acc:\n",
    "                    max_test_acc = test_acc\n",
    "                    if test_acc > max_test_acc_overall:\n",
    "                        if not os.path.exists('state_dict'):\n",
    "                            os.mkdir('state_dict')\n",
    "                        path = './state_dict/{0}_{1}_{2}class_acc{3:.4f}'.format(model_name, dataset, polarities_dim, test_acc)\n",
    "                        torch.save(model.state_dict(), path)\n",
    "                        print('model saved:', path)\n",
    "                if f1 > max_f1:\n",
    "                    max_f1 = f1\n",
    "                print('loss: {:.4f}, acc: {:.4f}, test_acc: {:.4f}, f1: {:.4f}'.format(loss.item(), train_acc, test_acc, f1))\n",
    "    return max_test_acc, max_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "190db6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    # switch model to evaluation mode\n",
    "    model.eval()\n",
    "    n_test_correct, n_test_total = 0, 0\n",
    "    t_targets_all, t_outputs_all = None, None\n",
    "    with torch.no_grad():\n",
    "        for t_batch, t_sample_batched in enumerate(test_dataloader):\n",
    "            t_inputs = [t_sample_batched[col].to(device) for col in input_cols]\n",
    "            t_targets = t_sample_batched['polarity'].to(device)\n",
    "            print(t_inputs)\n",
    "            break\n",
    "            t_outputs = model(t_inputs)\n",
    "\n",
    "            n_test_correct += (torch.argmax(t_outputs, -1) == t_targets).sum().item()\n",
    "            n_test_total += len(t_outputs)\n",
    "\n",
    "            t_targets_all = torch.cat((t_targets_all, t_targets), dim=0) if t_targets_all is not None else t_targets\n",
    "            t_outputs_all = torch.cat((t_outputs_all, t_outputs), dim=0) if t_outputs_all is not None else t_outputs\n",
    "    test_acc = n_test_correct / n_test_total\n",
    "    f1 = metrics.f1_score(t_targets_all.cpu(), torch.argmax(t_outputs_all, -1).cpu(), labels=[0, 1, 2], average='macro')\n",
    "    return test_acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d2c780b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat: 0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 0\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.4240\n",
      "loss: 0.9940, acc: 0.5000, test_acc: 0.4240, f1: 0.2005\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.4274\n",
      "loss: 1.0281, acc: 0.4766, test_acc: 0.4274, f1: 0.2003\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.5249\n",
      "loss: 1.0342, acc: 0.5000, test_acc: 0.5249, f1: 0.3840\n",
      "loss: 0.9486, acc: 0.5117, test_acc: 0.4979, f1: 0.3581\n",
      "loss: 0.9976, acc: 0.4938, test_acc: 0.5026, f1: 0.3358\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.5997\n",
      "loss: 1.0829, acc: 0.4870, test_acc: 0.5997, f1: 0.4544\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6280\n",
      "loss: 0.8143, acc: 0.5134, test_acc: 0.6280, f1: 0.4829\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 1\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6366\n",
      "loss: 0.9876, acc: 0.5469, test_acc: 0.6366, f1: 0.4911\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6628\n",
      "loss: 0.7488, acc: 0.6094, test_acc: 0.6628, f1: 0.5492\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6671\n",
      "loss: 0.8504, acc: 0.6302, test_acc: 0.6671, f1: 0.5465\n",
      "loss: 0.6964, acc: 0.6562, test_acc: 0.6628, f1: 0.5317\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6791\n",
      "loss: 0.7228, acc: 0.6687, test_acc: 0.6791, f1: 0.5452\n",
      "loss: 0.9143, acc: 0.6536, test_acc: 0.6778, f1: 0.5736\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6800\n",
      "loss: 0.7484, acc: 0.6540, test_acc: 0.6800, f1: 0.6281\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 2\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6916\n",
      "loss: 0.6933, acc: 0.6875, test_acc: 0.6916, f1: 0.5815\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.6937\n",
      "loss: 0.7009, acc: 0.6719, test_acc: 0.6937, f1: 0.5755\n",
      "loss: 1.0501, acc: 0.6406, test_acc: 0.6748, f1: 0.5873\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7019\n",
      "loss: 0.7289, acc: 0.6523, test_acc: 0.7019, f1: 0.6417\n",
      "loss: 0.8024, acc: 0.6438, test_acc: 0.7006, f1: 0.6265\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7113\n",
      "loss: 0.6392, acc: 0.6562, test_acc: 0.7113, f1: 0.6265\n",
      "loss: 0.6104, acc: 0.6629, test_acc: 0.6980, f1: 0.6700\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7290\n",
      "loss: 0.7764, acc: 0.6582, test_acc: 0.7290, f1: 0.6105\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 3\n",
      "loss: 0.6993, acc: 0.7188, test_acc: 0.7178, f1: 0.5994\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7354\n",
      "loss: 0.5671, acc: 0.7578, test_acc: 0.7354, f1: 0.6481\n",
      "loss: 0.7811, acc: 0.7240, test_acc: 0.7354, f1: 0.6603\n",
      "loss: 0.5853, acc: 0.7500, test_acc: 0.7341, f1: 0.6594\n",
      "loss: 0.5041, acc: 0.7594, test_acc: 0.7199, f1: 0.6665\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7564\n",
      "loss: 0.6875, acc: 0.7500, test_acc: 0.7564, f1: 0.7158\n",
      "loss: 0.6779, acc: 0.7366, test_acc: 0.7320, f1: 0.6952\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 4\n",
      "loss: 0.7072, acc: 0.7344, test_acc: 0.7259, f1: 0.6098\n",
      "loss: 0.6981, acc: 0.6953, test_acc: 0.7517, f1: 0.7070\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7715\n",
      "loss: 0.6736, acc: 0.7135, test_acc: 0.7715, f1: 0.7102\n",
      "loss: 0.5189, acc: 0.7344, test_acc: 0.7676, f1: 0.6863\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7762\n",
      "loss: 0.4903, acc: 0.7500, test_acc: 0.7762, f1: 0.7000\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.7822\n",
      "loss: 0.5776, acc: 0.7422, test_acc: 0.7822, f1: 0.7456\n",
      "loss: 0.5218, acc: 0.7522, test_acc: 0.7788, f1: 0.6977\n",
      "loss: 0.3513, acc: 0.7606, test_acc: 0.7809, f1: 0.7478\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 5\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8020\n",
      "loss: 0.4942, acc: 0.8125, test_acc: 0.8020, f1: 0.7681\n",
      "loss: 0.5653, acc: 0.8203, test_acc: 0.7917, f1: 0.7513\n",
      "loss: 0.4840, acc: 0.8073, test_acc: 0.7766, f1: 0.7391\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8071\n",
      "loss: 0.6838, acc: 0.7812, test_acc: 0.8071, f1: 0.7734\n",
      "loss: 0.5785, acc: 0.7781, test_acc: 0.7968, f1: 0.7591\n",
      "loss: 0.5836, acc: 0.7812, test_acc: 0.7977, f1: 0.7571\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8080\n",
      "loss: 0.6029, acc: 0.7790, test_acc: 0.8080, f1: 0.7791\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 6\n",
      "loss: 0.5223, acc: 0.8438, test_acc: 0.8007, f1: 0.7648\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8179\n",
      "loss: 0.4407, acc: 0.8281, test_acc: 0.8179, f1: 0.7889\n",
      "loss: 0.4557, acc: 0.8333, test_acc: 0.8110, f1: 0.7807\n",
      "loss: 0.5888, acc: 0.8164, test_acc: 0.7749, f1: 0.6802\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8213\n",
      "loss: 0.5512, acc: 0.8063, test_acc: 0.8213, f1: 0.7952\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8312\n",
      "loss: 0.4209, acc: 0.8151, test_acc: 0.8312, f1: 0.8041\n",
      "loss: 0.4479, acc: 0.8125, test_acc: 0.8015, f1: 0.7351\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 7\n",
      "loss: 0.4877, acc: 0.8281, test_acc: 0.8119, f1: 0.7843\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8316\n",
      "loss: 0.4445, acc: 0.8203, test_acc: 0.8316, f1: 0.8005\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8338\n",
      "loss: 0.4985, acc: 0.8177, test_acc: 0.8338, f1: 0.8001\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8376\n",
      "loss: 0.3007, acc: 0.8359, test_acc: 0.8376, f1: 0.8022\n",
      "loss: 0.5292, acc: 0.8219, test_acc: 0.8346, f1: 0.8074\n",
      "loss: 0.6748, acc: 0.8073, test_acc: 0.8303, f1: 0.7816\n",
      "loss: 0.4723, acc: 0.8013, test_acc: 0.8153, f1: 0.7982\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8389\n",
      "loss: 0.6063, acc: 0.7988, test_acc: 0.8389, f1: 0.8032\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 8\n",
      "loss: 0.4587, acc: 0.8125, test_acc: 0.8230, f1: 0.7648\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8436\n",
      "loss: 0.4233, acc: 0.8203, test_acc: 0.8436, f1: 0.8159\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8471\n",
      "loss: 0.5109, acc: 0.8073, test_acc: 0.8471, f1: 0.8253\n",
      "loss: 0.3830, acc: 0.8125, test_acc: 0.8398, f1: 0.8124\n",
      "loss: 0.5599, acc: 0.8000, test_acc: 0.8235, f1: 0.7890\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8544\n",
      "loss: 0.4229, acc: 0.8073, test_acc: 0.8544, f1: 0.8356\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8643\n",
      "loss: 0.4212, acc: 0.8058, test_acc: 0.8643, f1: 0.8393\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 9\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8746\n",
      "loss: 0.3880, acc: 0.8594, test_acc: 0.8746, f1: 0.8523\n",
      "loss: 0.2969, acc: 0.8984, test_acc: 0.8673, f1: 0.8463\n",
      "loss: 0.3870, acc: 0.8646, test_acc: 0.8647, f1: 0.8359\n",
      "loss: 0.2090, acc: 0.8867, test_acc: 0.8638, f1: 0.8454\n",
      "loss: 0.5837, acc: 0.8688, test_acc: 0.8471, f1: 0.8085\n",
      "loss: 0.5500, acc: 0.8516, test_acc: 0.8647, f1: 0.8455\n",
      "loss: 0.4670, acc: 0.8460, test_acc: 0.8574, f1: 0.8406\n",
      "loss: 0.3720, acc: 0.8453, test_acc: 0.8625, f1: 0.8308\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 10\n",
      "loss: 0.4996, acc: 0.7656, test_acc: 0.8698, f1: 0.8417\n",
      "loss: 0.3802, acc: 0.8281, test_acc: 0.8660, f1: 0.8494\n",
      "loss: 0.2243, acc: 0.8594, test_acc: 0.8655, f1: 0.8391\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8793\n",
      "loss: 0.2767, acc: 0.8711, test_acc: 0.8793, f1: 0.8608\n",
      "loss: 0.3084, acc: 0.8781, test_acc: 0.8759, f1: 0.8607\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8853\n",
      "loss: 0.3827, acc: 0.8672, test_acc: 0.8853, f1: 0.8682\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8952\n",
      "loss: 0.3318, acc: 0.8638, test_acc: 0.8952, f1: 0.8787\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 11\n",
      "loss: 0.1490, acc: 0.9688, test_acc: 0.8939, f1: 0.8800\n",
      "loss: 0.3264, acc: 0.8906, test_acc: 0.8754, f1: 0.8504\n",
      "loss: 0.2540, acc: 0.9010, test_acc: 0.8900, f1: 0.8710\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8965\n",
      "loss: 0.3241, acc: 0.8945, test_acc: 0.8965, f1: 0.8803\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.8982\n",
      "loss: 0.4162, acc: 0.8844, test_acc: 0.8982, f1: 0.8839\n",
      "loss: 0.5664, acc: 0.8568, test_acc: 0.8819, f1: 0.8696\n",
      "loss: 0.2081, acc: 0.8616, test_acc: 0.8879, f1: 0.8765\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 12\n",
      "loss: 0.2321, acc: 0.8906, test_acc: 0.8870, f1: 0.8617\n",
      "loss: 0.1519, acc: 0.9297, test_acc: 0.8875, f1: 0.8668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2797, acc: 0.9115, test_acc: 0.8909, f1: 0.8777\n",
      "loss: 0.4040, acc: 0.8984, test_acc: 0.8883, f1: 0.8663\n",
      "loss: 0.2551, acc: 0.9000, test_acc: 0.8900, f1: 0.8780\n",
      "loss: 0.3308, acc: 0.8854, test_acc: 0.8926, f1: 0.8818\n",
      "loss: 0.2624, acc: 0.8884, test_acc: 0.8913, f1: 0.8680\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.9021\n",
      "loss: 0.3938, acc: 0.8809, test_acc: 0.9021, f1: 0.8837\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 13\n",
      "loss: 0.2881, acc: 0.8906, test_acc: 0.8956, f1: 0.8836\n",
      "loss: 0.2523, acc: 0.8984, test_acc: 0.9021, f1: 0.8868\n",
      "loss: 0.1886, acc: 0.9115, test_acc: 0.8965, f1: 0.8736\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.9068\n",
      "loss: 0.2725, acc: 0.9102, test_acc: 0.9068, f1: 0.8950\n",
      "loss: 0.2241, acc: 0.9062, test_acc: 0.9042, f1: 0.8926\n",
      "loss: 0.2486, acc: 0.9010, test_acc: 0.8999, f1: 0.8778\n",
      "loss: 0.3338, acc: 0.8996, test_acc: 0.9029, f1: 0.8860\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 14\n",
      "loss: 0.2134, acc: 0.9062, test_acc: 0.8978, f1: 0.8875\n",
      "loss: 0.2706, acc: 0.8828, test_acc: 0.9055, f1: 0.8892\n",
      "loss: 0.2216, acc: 0.8906, test_acc: 0.8819, f1: 0.8489\n",
      "loss: 0.2527, acc: 0.8906, test_acc: 0.9021, f1: 0.8858\n",
      "loss: 0.3784, acc: 0.8812, test_acc: 0.8969, f1: 0.8862\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.9081\n",
      "loss: 0.1981, acc: 0.8906, test_acc: 0.9081, f1: 0.8943\n",
      "loss: 0.2424, acc: 0.8862, test_acc: 0.9076, f1: 0.8950\n",
      "loss: 0.4099, acc: 0.8814, test_acc: 0.9051, f1: 0.8937\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 15\n",
      "loss: 0.2073, acc: 0.9375, test_acc: 0.9025, f1: 0.8841\n",
      "loss: 0.2162, acc: 0.9141, test_acc: 0.9029, f1: 0.8864\n",
      "loss: 0.2146, acc: 0.9062, test_acc: 0.9068, f1: 0.8929\n",
      "loss: 0.2715, acc: 0.9023, test_acc: 0.9081, f1: 0.8944\n",
      "loss: 0.3010, acc: 0.8969, test_acc: 0.9081, f1: 0.8924\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.9094\n",
      "loss: 0.2072, acc: 0.9010, test_acc: 0.9094, f1: 0.8964\n",
      "loss: 0.3831, acc: 0.8884, test_acc: 0.9072, f1: 0.8953\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 16\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.9111\n",
      "loss: 0.2568, acc: 0.9062, test_acc: 0.9111, f1: 0.8982\n",
      "loss: 0.1342, acc: 0.9375, test_acc: 0.9016, f1: 0.8823\n",
      "loss: 0.2266, acc: 0.9323, test_acc: 0.9085, f1: 0.8943\n",
      "loss: 0.2494, acc: 0.9141, test_acc: 0.9102, f1: 0.8990\n",
      "loss: 0.3626, acc: 0.9031, test_acc: 0.9085, f1: 0.8934\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.9128\n",
      "loss: 0.2534, acc: 0.9062, test_acc: 0.9128, f1: 0.9000\n",
      "loss: 0.2463, acc: 0.9018, test_acc: 0.9111, f1: 0.9008\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 17\n",
      "loss: 0.2685, acc: 0.8906, test_acc: 0.9124, f1: 0.9011\n",
      "loss: 0.2187, acc: 0.8906, test_acc: 0.9046, f1: 0.8872\n",
      "loss: 0.3345, acc: 0.8906, test_acc: 0.9034, f1: 0.8858\n",
      "loss: 0.3112, acc: 0.8750, test_acc: 0.9051, f1: 0.8944\n",
      "loss: 0.1685, acc: 0.8812, test_acc: 0.9128, f1: 0.9028\n",
      "loss: 0.1982, acc: 0.8828, test_acc: 0.9107, f1: 0.8963\n",
      "loss: 0.2001, acc: 0.8839, test_acc: 0.9046, f1: 0.8859\n",
      "model saved: ./state_dict/pban_restaurant_3class_acc0.9141\n",
      "loss: 0.2445, acc: 0.8789, test_acc: 0.9141, f1: 0.9015\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 18\n",
      "loss: 0.2205, acc: 0.9219, test_acc: 0.9046, f1: 0.8958\n",
      "loss: 0.2573, acc: 0.9062, test_acc: 0.9102, f1: 0.8993\n",
      "loss: 0.2676, acc: 0.8854, test_acc: 0.9111, f1: 0.8953\n",
      "loss: 0.2356, acc: 0.8867, test_acc: 0.9128, f1: 0.8995\n",
      "loss: 0.1738, acc: 0.8938, test_acc: 0.9102, f1: 0.8986\n",
      "loss: 0.3674, acc: 0.8854, test_acc: 0.9038, f1: 0.8910\n",
      "loss: 0.3501, acc: 0.8728, test_acc: 0.9124, f1: 0.8966\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch: 19\n",
      "loss: 0.2382, acc: 0.8906, test_acc: 0.9115, f1: 0.8969\n",
      "loss: 0.1906, acc: 0.9141, test_acc: 0.9132, f1: 0.9013\n",
      "loss: 0.2391, acc: 0.9062, test_acc: 0.9137, f1: 0.9019\n",
      "loss: 0.1508, acc: 0.9141, test_acc: 0.9132, f1: 0.9010\n",
      "loss: 0.2287, acc: 0.9125, test_acc: 0.9111, f1: 0.8959\n",
      "loss: 0.1924, acc: 0.9167, test_acc: 0.9132, f1: 0.8983\n",
      "loss: 0.2587, acc: 0.9040, test_acc: 0.9098, f1: 0.9004\n",
      "loss: 0.1731, acc: 0.9047, test_acc: 0.9119, f1: 0.9021\n",
      "max_test_acc: 0.9140893470790378, max_f1: 0.902790987110194\n",
      "##################################################\n",
      "max_test_acc_overall: 0.9140893470790378\n",
      "max_f1_overall: 0.902790987110194\n"
     ]
    }
   ],
   "source": [
    "max_test_acc_overall = 0\n",
    "max_f1_overall = 0\n",
    "repeats = 1\n",
    "for i in range(repeats):\n",
    "    print('repeat:', i)\n",
    "    reset_params()\n",
    "    max_test_acc, max_f1 = train(criterion, optimizer, max_test_acc_overall)\n",
    "    print('max_test_acc: {0}, max_f1: {1}'.format(max_test_acc, max_f1))\n",
    "    max_test_acc_overall = max(max_test_acc, max_test_acc_overall)\n",
    "    max_f1_overall = max(max_f1, max_f1_overall)\n",
    "    print('#' * 50)\n",
    "print('max_test_acc_overall:', max_test_acc_overall)\n",
    "print('max_f1_overall:', max_f1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c5048dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': tensor([[ 820, 1214, 2046,  ...,    0,    0,    0],\n",
      "        [ 820, 1214, 2046,  ...,    0,    0,    0],\n",
      "        [1323,  243, 2856,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 311, 2171, 1323,  ...,    0,    0,    0],\n",
      "        [1323, 1286, 1677,  ...,    0,    0,    0],\n",
      "        [  68, 2888, 2209,  ...,    0,    0,    0]]), 'aspect': tensor([[2434,    0,    0,  ...,    0,    0,    0],\n",
      "        [1787, 1888,    0,  ...,    0,    0,    0],\n",
      "        [2512, 2148,    0,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 621,    0,    0,  ...,    0,    0,    0],\n",
      "        [1286,    0,    0,  ...,    0,    0,    0],\n",
      "        [1726, 1884,    0,  ...,    0,    0,    0]]), 'position': tensor([[ 9,  8,  7,  ...,  0,  0,  0],\n",
      "        [16, 15, 14,  ...,  0,  0,  0],\n",
      "        [ 6,  5,  4,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 3,  2,  1,  ...,  0,  0,  0],\n",
      "        [ 1,  0,  1,  ...,  0,  0,  0],\n",
      "        [ 8,  7,  6,  ...,  0,  0,  0]]), 'polarity': tensor([2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 0,\n",
      "        1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 1, 1, 0, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 1, 2])}\n"
     ]
    }
   ],
   "source": [
    "for i in test_dataloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a824d9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_dict = {0: 'positive', 1: 'negative', 2:'neutral'}\n",
    "sample_data = torch.tensor(tokenizer.text_to_sequence(\"Keyboard is great, very quiet for all the typing that I do.\"))\n",
    "output = model(sample_data.reshape(1,1,-1))\n",
    "polarity_dict[int(torch.argmax(output, -1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fef7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
